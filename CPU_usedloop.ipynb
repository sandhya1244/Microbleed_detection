{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_13036\\1351951873.py:99: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if pd.notnull(row[i]) and pd.notnull(row[i+1]) and pd.notnull(row[i+2]):\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_13036\\1351951873.py:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = int(row[i])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_13036\\1351951873.py:101: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = int(row[i+1])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_13036\\1351951873.py:102: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  z = int(row[i+2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (microbleed features): [[1.3276780452851649 0.059501643854425065 1.1525953933965267]\n",
      " [3.5164746765491715 0.06874614842956162 1.2223727390408345]\n",
      " [1.2413478213752323 0.24095702163075158 1.1663834703619909]\n",
      " [7.2733714236134155 2.360417275042322 0.9498957949370392]\n",
      " [7.423963066528856 5.9141870148825575 1.1231526178645026]\n",
      " [0.9905946447961975 2.324449476425768 1.1447708550999882]\n",
      " [4.611083561454144 14.582060850565261 1.218410447116826]\n",
      " [1.5388950650168207 0.22882646525011127 1.1932610478820673]\n",
      " [3.423855860550176 0.3158556359078843 1.2089103286719418]\n",
      " [4.496661698300447 0.05225530078641711 1.2241076919655154]\n",
      " [1.677782255801848 0.2742943717810373 1.207329777340929]\n",
      " [4.7239765229445245 2.0836324657704752 0.9474458039239336]\n",
      " [0.28684699070685366 0.6219987192967055 0.9069935945940483]\n",
      " [3.752050748743212 3.787796324608347 1.1625852731977937]\n",
      " [7.348563180719309 1.3362254314919335 0.9898079514774023]\n",
      " [2.427140119350558 0.3987253932815711 1.2237013541529884]\n",
      " [0.2966968729385904 2.745475032836281 0.9471075527048747]\n",
      " [2.3358759866067835 0.16337732734040863 1.219620095632783]\n",
      " [2.836858121212626 0.3646615828092867 0.9066844708810581]\n",
      " [9.125161822405193 0.13702058477971268 1.116050200318809]\n",
      " [10.55091972282055 0.7201728130622749 0.9890119862013039]\n",
      " [5.09838370030309 16.938447347729678 1.2175904698363276]\n",
      " [2.6887716266390185 2.085753142944415 1.2183749741740528]\n",
      " [1.3098732789707865 2.5091142351970035 1.1879976396504954]\n",
      " [7.920733770585887 17.451649345348944 1.193107522081414]\n",
      " [11.321814647302325 106.13094195857735 1.2236577046369204]\n",
      " [0.3604419984815748 0.25916070478987213 0.9871483340192279]\n",
      " [6.733324673982541 0.3346032654867547 1.1396068950462888]\n",
      " [2.9502544112303917 0.2375803579839621 1.2221172297563414]\n",
      " [3.5792316565531643 6.544777544334564 1.220584010267739]\n",
      " [4.012692643800409 0.27710458221932244 1.1987606476919421]\n",
      " [5.564505447189164 13.35562614760914 1.2123707791046985]\n",
      " [3.9344275904672608 2.429657014011868 1.1907679565859148]\n",
      " [0.9165126402128779 1.8527646788892225 1.1335228458966184]\n",
      " [1.3499412085928542 0.30479344408798026 1.224434369100398]\n",
      " [1.7741714022460011 0.5082620945610548 1.2205061273588214]\n",
      " [4.019987864599693 0.12249239344141431 1.2054857561169086]\n",
      " [6.287876914245641 0.4773710119957235 0.9543568192735362]\n",
      " [3.4412643827280536 0.11778434000141187 1.2171544219895758]\n",
      " [2.549018943421931 6.483284735879738 1.222379514018292]\n",
      " [3.500568954796376 0.11903838369627058 1.2158970458248595]\n",
      " [4.90214451991158 0.1737514524255514 1.1652077684288074]\n",
      " [3.98126701685822 0.2301356955429918 0.6717414196943985]\n",
      " [6.455742263868939 0.18302036855850506 1.1645186622122492]\n",
      " [1.7725023138966045 0.05172346698226374 1.148683408742879]\n",
      " [5.253172218185018 2.3541887523346587 1.1598063035001487]\n",
      " [13.09457147077526 0.04755696751697641 1.1495631552126973]\n",
      " [2.7462144326907665 2.4004979674324978 1.1559307112694606]\n",
      " [3.8940042629277913 0.23121143590054857 1.1689444975286996]\n",
      " [5.600484504580954 8.04761982320754 1.1943530671656437]\n",
      " [10.49336334117422 0.046705131047484846 1.174173025572842]\n",
      " [2.1491365665478424 0.14819519535350187 1.2123672899183335]\n",
      " [0.7069136447765793 0.46554458088194905 1.080050997204078]\n",
      " [0.7891789416793553 0.4048633277027112 1.1010296222374383]\n",
      " [0.34049441390811636 0.5639762227367678 0.9388364130769059]\n",
      " [3.997050520577223 0.23893530652439338 1.2031543810409755]\n",
      " [5.7931066503572675 12.612019251108773 1.2076682957378602]\n",
      " [3.828020261535017 0.9029348036217958 1.018107898929327]\n",
      " [4.156137226520808 7.351899271457224 1.2151650497720223]\n",
      " [2.3609190597610277 2.196835976370549 1.2237111323315797]\n",
      " [2.5809066662242133 0.0889223705808952 1.222189800104081]\n",
      " [7.976647862666384 21.178830761899604 1.1933046671209906]\n",
      " [3.316370142594054 16.685015075319853 1.2171686970252442]\n",
      " [3.337176422978012 10.111375611607802 1.224508718252374]\n",
      " [2.517018142611992 0.07606423335526177 1.2045694126336381]\n",
      " [4.403168214541184 8.975712885308432 1.2028201483584533]\n",
      " [1.065655611746912 1.351700476369243 1.1653644452596568]\n",
      " [1.2245413553872955 0.038635674628568664 1.095218349894887]\n",
      " [1.4807743129009272 4.643159285786624 1.186655743070885]\n",
      " [1.2877815668853905 0.8854638214877101 1.1959232657301098]\n",
      " [4.075024873001468 0.24639918089601448 1.1591724533466017]\n",
      " [2.0050289563514108 1.605068013838412 1.2246592144782757]\n",
      " [4.260494421421993 4.045706767125957 1.1541175513950805]\n",
      " [2.2300945884188237 6.0852233803178715 1.2172226871103948]\n",
      " [4.3104643834135095 0.1523583545846897 1.2097674048608476]\n",
      " [1.7802933628541293 5.437134583424868 1.2022211821755124]\n",
      " [1.6451557851650993 2.844952890932775 1.210747031382927]\n",
      " [0.05603825811714991 0.3609286682465804 0.8494034816004602]\n",
      " [17.932215100271232 0.02708312546431749 1.1395133060203346]\n",
      " [1.9991408946427465 1.334517922536009 1.2247290435922402]\n",
      " [1.6357614234940447 2.0012984111898606 1.2154038140940744]\n",
      " [1.4998302448025187 3.812096210294205 1.1943210122271688]\n",
      " [0.783761927952067 2.3956489627797772 1.0999639812362]\n",
      " [5.934047269661769 0.12453219091352115 1.1886852277120776]\n",
      " [1.4217839101738463 0.37282812443002583 1.1969587087917977]\n",
      " [3.108251505743857 0.6952437684350219 1.086784874527628]\n",
      " [0.959491565835113 0.38487553093939836 1.1368838096615559]\n",
      " [1.882498195661492 0.24430335406052828 1.214258075467593]\n",
      " [2.569991230716964 2.217191823890542 1.2210500489348215]\n",
      " [2.3856659126259783 1.6880170446802614 1.2221731980167267]\n",
      " [3.0796870129702016 3.384339391799364 1.217200611428957]\n",
      " [1.2521967884029408 3.9071749429516904 1.1695860312189903]\n",
      " [1.2213045369507336 2.440391700541779 1.1786316918716098]\n",
      " [3.41513117363155 5.269500371486626 1.1955626497809018]\n",
      " [0.4850990927730091 2.39277994389899 1.0104481567967782]\n",
      " [1.6392085063303863 3.2549686618645928 1.2077302385774937]\n",
      " [4.2635384545995825 0.06750689078961704 1.2219320461320118]\n",
      " [5.60935678641671 0.06761680825340052 1.2147407303922986]\n",
      " [1.5021606793497941 3.2061637640956366 1.1991235176555604]\n",
      " [2.6483599490899237 0.9450495575967509 1.0618396733903004]\n",
      " [10.114131485768086 17.242704738969856 1.1572217026111093]\n",
      " [6.555960041460331 0.9124093940244876 1.0176395677931582]\n",
      " [22.9708799356666 61.41916480896416 1.1411900211234367]\n",
      " [6.545928170095083 17.947958170175298 1.2102387461850983]\n",
      " [7.057993538615346 0.3762659426437842 1.0745790447773407]\n",
      " [1.4920585395940005 1.2470439851333468 1.211758491738205]\n",
      " [3.446269526889588 0.3137670010631811 1.2085503843631804]\n",
      " [5.36219063886989 3.93504304305525 1.1274733445759328]\n",
      " [2.01461531901015 5.918752842975977 1.2108308259672655]\n",
      " [5.7212809863464384 2.810197715954413 1.0954225060103333]\n",
      " [71.3549263054698 0.08254872497198484 1.0259054811801502]\n",
      " [2.5722852966670935 0.3064772266353077 1.2238410218081222]\n",
      " [5.202831261006742 0.6845964122025471 1.0498172590591535]\n",
      " [6.457754270585147 10.54495396189984 1.1914380499493527]\n",
      " [8.365573341042642 16.626991657279728 1.185628128529814]\n",
      " [3.021643779248911 0.11649034709870104 1.2225963414353909]\n",
      " [2.038248712340942 0.9547798363738157 1.0852412945679135]\n",
      " [1.0194029714058592 0.36345176492278886 1.1464159033517998]\n",
      " [1.993661952917579 0.13989065928428907 1.2044424787249413]\n",
      " [9.402742170796797 34.041635086342765 1.2012124668706914]\n",
      " [1.265784228820918 0.16464472822505727 1.2082649020046476]\n",
      " [2.8730900913756443 4.491387139282267 1.2008672664992104]\n",
      " [3.363952954738314 5.429416996623707 1.2203284038323448]\n",
      " [1.423648847926145 2.775385223101467 1.1963459837925565]\n",
      " [0.6935891213386677 0.2988487436997631 1.0756528947116393]\n",
      " [0.5594347045646458 0.22497639080699328 1.0436794125153006]\n",
      " [9.011369789123446 18.431725974321537 1.1734794451294377]\n",
      " [1.6786282798857546 0.3469365516154396 1.2121965838724724]\n",
      " [6.639102456725712 5.7334898055684045 1.1325063243205118]\n",
      " [2.761151840100898 0.05440023580684033 1.2115777480731842]\n",
      " [5.410562461480316 2.301280637392659 0.9414077963352787]\n",
      " [1.6094378922355301 0.21952076673320153 1.197080938187059]\n",
      " [5.42391216814266 0.29920965080170914 1.113748558790848]\n",
      " [6.0036618221279525 2.832387502966242 0.9267491723350167]\n",
      " [4.653234477443727 0.07592329849085551 1.2214638074139121]\n",
      " [1.885784066941368 0.7541652343385867 1.2240929465323622]\n",
      " [1.704872202393664 1.5050821511401948 1.2201676835207862]\n",
      " [1.6274653090853566 1.7964922738796423 1.216118368572147]\n",
      " [6.288129559480259 3.0484745635563932 0.9227127822239998]\n",
      " [4.499637237768004 16.033933038514924 1.2216224254038335]\n",
      " [4.69206601230002 9.907389301269623 1.21511426320451]\n",
      " [3.2846787192177356 1.3732627700066082 1.0764474863766487]\n",
      " [3.9350303170205136 3.691607289565001 1.1553733424270263]\n",
      " [0.17538123663714694 0.6092708785811046 0.8486201301456388]\n",
      " [0.59625673902058 1.991791064123587 1.045297774654933]\n",
      " [8.238297251025402 0.0931331835376272 1.1505536006277615]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import ndimage\n",
    "\n",
    "X = []\n",
    "# Define a function to extract ROIs around microbleed locations\n",
    "def extract_roi(swi_data, coordinates, roi_size):\n",
    "    rois = []\n",
    "    for coord in coordinates:\n",
    "        x, y, z = coord\n",
    "        # Ensure the ROI stays within the image bounds\n",
    "        x_start = max(0, x - roi_size // 2)\n",
    "        x_end = min(swi_data.shape[0], x + (roi_size + 1) // 2)\n",
    "        y_start = max(0, y - roi_size // 2)\n",
    "        y_end = min(swi_data.shape[1], y + (roi_size + 1) // 2)\n",
    "        z_start = max(0, z - roi_size // 2)\n",
    "        z_end = min(swi_data.shape[2], z + (roi_size + 1) // 2)\n",
    "        \n",
    "        # Extract the ROI from the image data\n",
    "        roi = swi_data[x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "        rois.append(roi)\n",
    "    return rois\n",
    "\n",
    "# Define a function to compute Hessian matrix eigenvalues\n",
    "def compute_hessian_eigenvalues(roi):\n",
    "    # Apply Gaussian filter to the ROI for smoothing\n",
    "    smoothed_roi = gaussian_filter(roi, sigma=1)\n",
    "    \n",
    "    # Compute gradients along x, y, and z directions using Sobel filters\n",
    "    gradient_x = ndimage.sobel(smoothed_roi, axis=0)\n",
    "    gradient_y = ndimage.sobel(smoothed_roi, axis=1)\n",
    "    gradient_z = ndimage.sobel(smoothed_roi, axis=2)\n",
    "    \n",
    "    # Compute second derivatives along x, y, and z directions\n",
    "    dxx = ndimage.sobel(gradient_x, axis=0)\n",
    "    dyy = ndimage.sobel(gradient_y, axis=1)\n",
    "    dzz = ndimage.sobel(gradient_z, axis=2)\n",
    "    dxy = ndimage.sobel(gradient_x, axis=1)\n",
    "    dxz = ndimage.sobel(gradient_x, axis=2)\n",
    "    dyz = ndimage.sobel(gradient_y, axis=2)\n",
    "    \n",
    "    # Construct the Hessian matrix\n",
    "    Hessian_matrix = np.array([\n",
    "        [dxx.mean(), dxy.mean(), dxz.mean()],\n",
    "        [dxy.mean(), dyy.mean(), dyz.mean()],\n",
    "        [dxz.mean(), dyz.mean(), dzz.mean()]\n",
    "    ])\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors of the Hessian matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(Hessian_matrix)\n",
    "    \n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "# Define a function to compute Hessian shape features\n",
    "def compute_hessian_shape_features(eigenvalues):\n",
    "    if len(eigenvalues) != 3:\n",
    "        # If the number of eigenvalues is not 3, return default values or handle the case accordingly\n",
    "        print(\"Invalid number of eigenvalues for computing features\")\n",
    "        return 0, 0, 0  # Return default values or handle differently if needed\n",
    "    \n",
    "    # Sphericalness feature\n",
    "    f_sphere = abs(eigenvalues[0]) / np.sqrt(abs(eigenvalues[1] * eigenvalues[2]))\n",
    "    \n",
    "    # Largest cross-section feature\n",
    "    f_lc = abs(eigenvalues[1]) / abs(eigenvalues[2])\n",
    "    \n",
    "    # Fractional anisotropy feature\n",
    "    f_fa = np.sqrt(0.5) * np.sqrt((eigenvalues[0] - eigenvalues[1])**2 + \n",
    "                                  (eigenvalues[1] - eigenvalues[2])**2 + \n",
    "                                  (eigenvalues[0] - eigenvalues[2])**2) / np.sqrt((eigenvalues[0]**2 + eigenvalues[1]**2 + eigenvalues[2]**2))\n",
    "    \n",
    "    return f_sphere, f_lc, f_fa\n",
    "\n",
    "# Load the Excel file containing microbleed coordinates\n",
    "excel_file = 'micro-location.xlsx'  # Replace with your Excel file path\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Path to the folder containing the NIFTI images\n",
    "folder_path = 'rCMB'  # Replace 'path_to_rCMB_folder' with your folder path\n",
    "\n",
    "# Iterate through rows to load NIFTI files and extract microbleed features\n",
    "for index, row in df.iterrows():\n",
    "    nifti_filename = row['NIFTI']  # Assuming 'NIFTI' is the column name containing the NIFTI file names\n",
    "    nifti_path = os.path.join(folder_path, nifti_filename)\n",
    "\n",
    "    # Check if the NIFTI file exists in the folder\n",
    "    if os.path.exists(nifti_path):\n",
    "        swi_img = nib.load(nifti_path)\n",
    "        swi_data = swi_img.get_fdata()\n",
    "\n",
    "        # Extract microbleed coordinates for the current NIFTI file\n",
    "        microbleed_coordinates = []\n",
    "        for i in range(1, len(row), 3):\n",
    "            try:\n",
    "                if pd.notnull(row[i]) and pd.notnull(row[i+1]) and pd.notnull(row[i+2]):\n",
    "                    x = int(row[i])\n",
    "                    y = int(row[i+1])\n",
    "                    z = int(row[i+2])\n",
    "                    microbleed_coordinates.append((x, y, z))\n",
    "            except (ValueError, TypeError):\n",
    "                pass  # Skip non-numeric or empty values\n",
    "\n",
    "        # Process microbleed coordinates for the current NIFTI file\n",
    "        #print(f\"NIFTI Filename: {nifti_filename}\")\n",
    "        #print(f\"Microbleed Coordinates: {microbleed_coordinates}\")\n",
    "        #print(f\"SWI Image Shape: {swi_data.shape}\")\n",
    "        \n",
    "        # Define the size of the ROI around each microbleed\n",
    "        roi_size = 10  # Adjust this according to your desired size\n",
    "\n",
    "        # Extract ROIs around microbleed locations\n",
    "        microbleed_rois = extract_roi(swi_data, microbleed_coordinates, roi_size)\n",
    "\n",
    "        # Compute Hessian matrix and eigenvalues for each ROI\n",
    "        eigenvalues_list = []\n",
    "        for roi in microbleed_rois:\n",
    "            eigenvalues = compute_hessian_eigenvalues(roi)\n",
    "            eigenvalues_list.append(eigenvalues)\n",
    "\n",
    "        # Compute Hessian shape features for each microbleed\n",
    "        hessian_shape_features_microbleed = []\n",
    "        for i, eigenvals_tuple in enumerate(eigenvalues_list):\n",
    "            eigenvals = eigenvals_tuple[0]  # Unpack the nested structure\n",
    "            if len(eigenvals) != 3:\n",
    "                # Print the invalid eigenvalues and their count for inspection\n",
    "                print(f\"Invalid eigenvalues at index {i+1}: {eigenvals} (Count: {len(eigenvals)})\")\n",
    "                continue\n",
    "            \n",
    "            f_sphere, f_lc, f_fa = compute_hessian_shape_features(eigenvals)\n",
    "            hessian_shape_features_microbleed.append((f_sphere, f_lc, f_fa))\n",
    "\n",
    "        # Append the computed features to the main feature list (X)\n",
    "        X.extend(hessian_shape_features_microbleed)\n",
    "\n",
    "# Convert the list of microbleed features to a NumPy array\n",
    "X1 = np.array(X,  dtype=object)\n",
    "\n",
    "# Display the shape of the resulting feature array\n",
    "print(f\"Shape of X (microbleed features): {X1}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualize individual slices for the first four ROIs\n",
    "for i in range(2):\n",
    "    roi = microbleed_rois[i]\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Coronal View\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(roi[:, :, roi.shape[2]//2], cmap='gray')\n",
    "    plt.title(f\"ROI {i+1} - Coronal View\")\n",
    "\n",
    "    # Axial View\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(roi[roi.shape[0]//2, :, :], cmap='gray')\n",
    "    plt.title(f\"ROI {i+1} - Axial View\")\n",
    "\n",
    "    # Sagittal View\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(roi[:, roi.shape[2]//2, :], cmap='gray')\n",
    "    plt.title(f\"ROI {i+1} - Sagittal View\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (microbleed features): []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import ndimage\n",
    "\n",
    "X = []\n",
    "# Define a function to extract ROIs around microbleed locations\n",
    "def extract_roi(swi_data, coordinates, roi_size):\n",
    "    rois = []\n",
    "    for coord in coordinates:\n",
    "        x, y, z = coord\n",
    "        # Ensure the ROI stays within the image bounds\n",
    "        x_start = max(0, x - roi_size // 2)\n",
    "        x_end = min(swi_data.shape[0], x + (roi_size + 1) // 2)\n",
    "        y_start = max(0, y - roi_size // 2)\n",
    "        y_end = min(swi_data.shape[1], y + (roi_size + 1) // 2)\n",
    "        z_start = max(0, z - roi_size // 2)\n",
    "        z_end = min(swi_data.shape[2], z + (roi_size + 1) // 2)\n",
    "        \n",
    "        # Extract the ROI from the image data\n",
    "        roi = swi_data[x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "        rois.append(roi)\n",
    "    return rois\n",
    "\n",
    "# Define a function to compute Hessian matrix eigenvalues\n",
    "def compute_hessian_eigenvalues(roi):\n",
    "    # Apply Gaussian filter to the ROI for smoothing\n",
    "    smoothed_roi = gaussian_filter(roi, sigma=1)\n",
    "    \n",
    "    # Compute gradients along x, y, and z directions using Sobel filters\n",
    "    gradient_x = ndimage.sobel(smoothed_roi, axis=0)\n",
    "    gradient_y = ndimage.sobel(smoothed_roi, axis=1)\n",
    "    gradient_z = ndimage.sobel(smoothed_roi, axis=2)\n",
    "    \n",
    "    # Compute second derivatives along x, y, and z directions\n",
    "    dxx = ndimage.sobel(gradient_x, axis=0)\n",
    "    dyy = ndimage.sobel(gradient_y, axis=1)\n",
    "    dzz = ndimage.sobel(gradient_z, axis=2)\n",
    "    dxy = ndimage.sobel(gradient_x, axis=1)\n",
    "    dxz = ndimage.sobel(gradient_x, axis=2)\n",
    "    dyz = ndimage.sobel(gradient_y, axis=2)\n",
    "    \n",
    "    # Construct the Hessian matrix\n",
    "    Hessian_matrix = np.array([\n",
    "        [dxx.mean(), dxy.mean(), dxz.mean()],\n",
    "        [dxy.mean(), dyy.mean(), dyz.mean()],\n",
    "        [dxz.mean(), dyz.mean(), dzz.mean()]\n",
    "    ])\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors of the Hessian matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(Hessian_matrix)\n",
    "    \n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "# Define a function to compute Hessian shape features\n",
    "def compute_hessian_shape_features(eigenvalues):\n",
    "    if len(eigenvalues) != 3:\n",
    "        # If the number of eigenvalues is not 3, return default values or handle the case accordingly\n",
    "        print(\"Invalid number of eigenvalues for computing features\")\n",
    "        return 0, 0, 0  # Return default values or handle differently if needed\n",
    "    \n",
    "    # Sphericalness feature\n",
    "    f_sphere = abs(eigenvalues[0]) / np.sqrt(abs(eigenvalues[1] * eigenvalues[2]))\n",
    "    \n",
    "    # Largest cross-section feature\n",
    "    f_lc = abs(eigenvalues[1]) / abs(eigenvalues[2])\n",
    "    \n",
    "    # Fractional anisotropy feature\n",
    "    f_fa = np.sqrt(0.5) * np.sqrt((eigenvalues[0] - eigenvalues[1])**2 + \n",
    "                                  (eigenvalues[1] - eigenvalues[2])**2 + \n",
    "                                  (eigenvalues[0] - eigenvalues[2])**2) / np.sqrt((eigenvalues[0]**2 + eigenvalues[1]**2 + eigenvalues[2]**2))\n",
    "    \n",
    "    return f_sphere, f_lc, f_fa\n",
    "\n",
    "# Load the Excel file containing microbleed coordinates\n",
    "excel_file = 'micro-location.xlsx'  # Replace with your Excel file path\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Path to the folder containing the NIFTI images\n",
    "folder_path = 'rCMB'  # Replace 'path_to_rCMB_folder' with your folder path\n",
    "\n",
    "# Iterate through rows to load NIFTI files and extract microbleed features\n",
    "for index, row in df.iterrows():\n",
    "    nifti_filename = row['NIFTI']  # Assuming 'NIFTI' is the column name containing the NIFTI file names\n",
    "    nifti_path = os.path.join(folder_path, nifti_filename)\n",
    "\n",
    "    # Check if the NIFTI file exists in the folder\n",
    "    if os.path.exists(nifti_path):\n",
    "        swi_img = nib.load(nifti_path)\n",
    "        swi_data = swi_img.get_fdata()\n",
    "\n",
    "        # Extract microbleed coordinates for the current NIFTI file\n",
    "        microbleed_coordinates = []\n",
    "        for i in range(1, len(row), 3):\n",
    "            try:\n",
    "                if pd.notnull(row[i]) and pd.notnull(row[i+1]) and pd.notnull(row[i+2]):\n",
    "                    x = int(row[i])\n",
    "                    y = int(row[i+1])\n",
    "                    z = int(row[i+2])\n",
    "                    microbleed_coordinates.append((x, y, z))\n",
    "            except (ValueError, TypeError):\n",
    "                pass  # Skip non-numeric or empty values\n",
    "\n",
    "        # Define the size of the ROI around each microbleed\n",
    "        roi_size = 10  # Adjust this according to your desired size\n",
    "\n",
    "        # Extract ROIs around microbleed locations\n",
    "        microbleed_rois = extract_roi(swi_data, microbleed_coordinates, roi_size)\n",
    "\n",
    "        # Compute Hessian matrix and eigenvalues for each ROI\n",
    "        eigenvalues_list = []\n",
    "        for roi in microbleed_rois:\n",
    "            eigenvalues = compute_hessian_eigenvalues(roi)\n",
    "            eigenvalues_list.append(eigenvalues)\n",
    "\n",
    "        # Compute Hessian shape features for each microbleed\n",
    "        hessian_shape_features_microbleed = []\n",
    "        for i, eigenvals_tuple in enumerate(eigenvalues_list):\n",
    "            eigenvals = eigenvals_tuple[0]  # Unpack the nested structure\n",
    "            if len(eigenvals) != 3:\n",
    "                # Print the invalid eigenvalues and their count for inspection\n",
    "                print(f\"Invalid eigenvalues at index {i+1}: {eigenvals} (Count: {len(eigenvals)})\")\n",
    "                continue\n",
    "            \n",
    "            f_sphere, f_lc, f_fa = compute_hessian_shape_features(eigenvals)\n",
    "            hessian_shape_features_microbleed.append((f_sphere, f_lc, f_fa))\n",
    "\n",
    "        # Append the computed features to the main feature list (X)\n",
    "        X.extend(hessian_shape_features_microbleed)\n",
    "\n",
    "# Convert the list of microbleed features to a NumPy array\n",
    "X1 = np.array(X)\n",
    "\n",
    "# Display the shape of the resulting feature array\n",
    "print(f\"Shape of X (microbleed features): {X1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y1 (labels): (0,)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Assuming X contains the microbleed features\n",
    "\n",
    "# Determine the number of microbleeds in X\n",
    "num_microbleeds = X1.shape[0]\n",
    "\n",
    "# Set the labels for microbleeds as 1\n",
    "Y1 = np.ones(num_microbleeds)\n",
    "\n",
    "# Display the shape of the label array\n",
    "print(f\"Shape of Y1 (labels): {Y1.shape}\")\n",
    "\n",
    "# Display a few labels to confirm that \n",
    "print(Y1)  # Displaying the first 10 labels as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_3320\\3917686042.py:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if pd.notnull(row[i]) and pd.notnull(row[i+1]) and pd.notnull(row[i+2]):\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_3320\\3917686042.py:101: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = int(row[i])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_3320\\3917686042.py:102: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = int(row[i+1])\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_3320\\3917686042.py:103: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  z = int(row[i+2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (non microbleed features): [[6.36109412e+00 1.78485560e-01 1.16708038e+00]\n",
      " [2.18786517e+00 4.15165032e-01 1.22474295e+00]\n",
      " [1.77420719e+00 6.44962652e-02 1.15926498e+00]\n",
      " [6.12282670e+00 4.42516792e+00 1.12263418e+00]\n",
      " [3.54654334e+00 2.55395797e-01 1.21091053e+00]\n",
      " [3.20422375e+01 4.65079151e-02 9.30486840e-01]\n",
      " [1.13090149e+00 4.50172400e-01 1.16858960e+00]\n",
      " [1.53420204e+01 1.31399581e+01 1.10032242e+00]\n",
      " [1.62912810e+00 5.10285691e+00 1.19485660e+00]\n",
      " [1.02637239e-01 5.01151327e-01 1.19487107e+00]\n",
      " [3.18729385e+00 1.96003616e-01 1.19965543e+00]\n",
      " [4.38224643e+00 2.17180186e+00 7.22686025e-01]\n",
      " [1.34485269e+00 2.44519517e+00 1.19205404e+00]\n",
      " [1.36619914e+00 2.66923884e+00 1.19214418e+00]\n",
      " [5.28601971e+00 7.77699313e+00 1.19841611e+00]\n",
      " [1.36477608e+00 5.06644341e-01 1.19787667e+00]\n",
      " [2.10604068e+00 8.25989285e-01 1.22444871e+00]\n",
      " [1.39458267e+00 1.07980262e+00 1.10725211e+00]\n",
      " [4.14219438e+00 1.73409370e+01 1.22433874e+00]\n",
      " [3.64922051e+00 1.75394073e+00 1.19215173e+00]\n",
      " [7.34836621e+00 8.89505411e-02 1.18126342e+00]\n",
      " [2.78859880e+00 2.16963018e+00 1.21676669e+00]\n",
      " [1.50252327e+00 6.67733841e-01 1.21129323e+00]\n",
      " [7.16026322e+00 4.68725236e+00 1.11126390e+00]\n",
      " [4.32796826e+00 2.59737549e+00 1.18273104e+00]\n",
      " [4.41357537e+00 1.52306772e+01 1.22436407e+00]\n",
      " [3.87935341e+00 2.47731911e-01 1.16404042e+00]\n",
      " [9.61344867e-01 4.46059363e-01 1.13991258e+00]\n",
      " [5.97130673e+00 9.88391935e-01 1.01410416e+00]\n",
      " [8.17712730e+00 6.04276963e+00 1.11500764e+00]\n",
      " [1.11021284e+01 7.06315464e+00 1.11826565e+00]\n",
      " [1.60130031e+01 2.75921649e-02 1.15051904e+00]\n",
      " [2.55478191e+00 4.60197149e+00 1.22468725e+00]\n",
      " [6.89061191e+00 5.96510440e+00 1.16097944e+00]\n",
      " [8.43133195e+00 1.10929929e+01 1.16616746e+00]\n",
      " [4.05899800e+00 1.13673097e+00 1.04030163e+00]\n",
      " [5.65641675e+00 1.04450632e+01 1.20308452e+00]\n",
      " [7.21228071e+00 5.12445255e+00 1.15016375e+00]\n",
      " [1.13552839e+00 4.27389146e-01 1.16818843e+00]\n",
      " [1.61527680e+00 1.53060380e-01 1.18514396e+00]\n",
      " [5.33654196e-01 5.45982508e-01 1.02165283e+00]\n",
      " [3.34474682e+00 3.81356484e-01 1.14305952e+00]\n",
      " [1.07252772e+01 9.33988270e+01 1.22384673e+00]\n",
      " [1.41228797e+00 1.11085998e+00 1.10116492e+00]\n",
      " [7.48719685e+00 6.49491511e-01 9.80439987e-01]\n",
      " [1.01779408e+01 6.55194501e+00 1.12391703e+00]\n",
      " [8.17939144e+00 4.32785543e+00 1.13099078e+00]\n",
      " [5.28867628e+00 1.79971297e+00 1.15368221e+00]\n",
      " [7.86256254e+00 8.17135087e-02 1.16368701e+00]\n",
      " [6.14948617e+00 3.50788180e-01 1.09028221e+00]\n",
      " [4.18420286e+00 4.27570717e+00 1.16037884e+00]\n",
      " [4.78854162e+00 4.15423091e+00 1.18598626e+00]\n",
      " [1.88098235e+00 2.73226431e+00 1.22036652e+00]\n",
      " [6.55756118e+00 1.05989023e-01 1.18530754e+00]\n",
      " [1.40412274e+00 5.26123430e-01 1.20179745e+00]\n",
      " [1.83150077e+00 2.18853346e-01 1.20963731e+00]\n",
      " [4.17351161e+00 3.11456717e+00 1.19106805e+00]\n",
      " [8.93864607e-01 6.24586394e-01 1.12999106e+00]\n",
      " [2.69764267e+00 1.55388430e+00 1.21564001e+00]\n",
      " [5.86004541e+00 2.32200256e-01 8.86317996e-01]\n",
      " [3.65081924e+00 5.82982189e-02 1.22115560e+00]\n",
      " [2.73427372e+00 2.84582289e-01 1.22281614e+00]\n",
      " [1.91280344e+00 4.13227227e+00 1.21519253e+00]\n",
      " [9.35689171e+00 8.96147436e-02 1.13935658e+00]\n",
      " [2.77902092e+00 8.79571908e+00 1.22137148e+00]\n",
      " [1.00169183e+00 2.52992710e+00 1.14512733e+00]\n",
      " [1.85594542e+00 1.41109064e-01 1.19773461e+00]\n",
      " [4.86570598e+00 2.05630581e+00 1.08390549e+00]\n",
      " [3.67849833e+00 2.48976732e-01 1.20879437e+00]\n",
      " [4.28195554e+00 1.81859465e-01 1.20519443e+00]\n",
      " [1.17704022e+00 6.81327866e-01 1.18127145e+00]\n",
      " [5.23670257e+00 8.15763548e-01 9.98842063e-01]\n",
      " [3.12420703e+00 2.31711069e-01 1.22017553e+00]\n",
      " [2.90576076e-01 1.57883394e-01 9.88279468e-01]\n",
      " [6.43614977e-01 2.64612186e-01 1.06330225e+00]\n",
      " [2.91664196e+00 7.50773990e+00 1.22429637e+00]\n",
      " [1.65780041e+01 4.88386400e-01 9.32254938e-01]\n",
      " [1.40246898e+00 2.52172705e-01 1.18480363e+00]\n",
      " [5.90001564e-01 6.13607644e-01 1.04072379e+00]\n",
      " [2.38156914e+00 3.54238931e-01 1.18533153e+00]\n",
      " [6.56167556e-01 1.94698081e+00 1.06463767e+00]\n",
      " [5.90804094e+00 1.80598043e+00 1.05920755e+00]\n",
      " [2.82399495e+00 5.02108360e-01 1.21503826e+00]\n",
      " [2.61614926e+00 2.55292750e-01 1.20032609e+00]\n",
      " [1.43736127e+00 1.95029141e-01 1.22063434e+00]\n",
      " [5.37814299e+00 4.61651936e+00 1.17763962e+00]\n",
      " [3.11007015e+00 8.77269848e+00 1.22435015e+00]\n",
      " [2.13369544e+00 2.22330153e-01 1.21956849e+00]\n",
      " [4.69504493e+00 1.74838044e-01 1.19849288e+00]\n",
      " [1.90665091e+00 3.40504505e+00 1.21830063e+00]\n",
      " [1.23995348e+00 1.98032880e+00 1.18499257e+00]\n",
      " [7.22970914e-01 3.38573299e-01 1.08343895e+00]\n",
      " [6.62173860e+00 3.62437942e+00 8.01368466e-01]\n",
      " [5.39064240e+00 2.55722908e-01 1.17166026e+00]\n",
      " [5.88550719e+00 5.32747199e-02 1.21253507e+00]\n",
      " [4.31250631e+00 1.71902080e-01 1.17940416e+00]\n",
      " [4.72579570e+00 2.60574970e-01 1.13878167e+00]\n",
      " [2.56717885e+00 8.69498937e+00 1.21784137e+00]\n",
      " [6.76647888e-01 5.72482124e-01 1.07064968e+00]\n",
      " [2.45097409e+00 2.95620176e-01 1.22464728e+00]\n",
      " [1.08337703e+00 4.72125239e-01 1.16232260e+00]\n",
      " [3.03808352e+00 4.08894647e+00 1.22064608e+00]\n",
      " [2.61335550e+01 4.27326662e-03 1.19799814e+00]\n",
      " [1.28042818e+00 5.69467444e-01 1.19139578e+00]\n",
      " [4.45335871e+00 5.66015230e-01 1.17179280e+00]\n",
      " [8.08188046e+00 4.86942173e-01 1.11312670e+00]\n",
      " [1.34570106e+00 2.52261925e-01 1.17930247e+00]\n",
      " [4.37383974e+00 1.15219555e+00 1.16933681e+00]\n",
      " [1.51429517e+01 2.48415544e-02 1.16242888e+00]\n",
      " [2.02032599e+00 2.11204286e+00 9.58183974e-01]\n",
      " [2.86294111e+00 7.73156069e+00 1.22376721e+00]\n",
      " [6.46434879e+00 5.89542970e-01 1.13179154e+00]\n",
      " [1.68918688e+00 4.25300068e+00 1.20410275e+00]\n",
      " [1.42445808e+00 2.93797571e+00 1.19507342e+00]\n",
      " [2.17243371e+00 3.03659626e+00 1.22422118e+00]\n",
      " [2.68272482e+00 4.55416553e-01 1.14950721e+00]\n",
      " [2.36990674e+00 4.74244247e+00 1.22336730e+00]\n",
      " [4.24692374e+00 1.87177035e+01 1.22420971e+00]\n",
      " [3.52937208e+00 5.19520505e-01 1.10679824e+00]\n",
      " [6.09675556e+00 2.56793360e+01 1.21985152e+00]\n",
      " [9.70332339e+00 3.30945562e-02 1.19787507e+00]\n",
      " [6.27297746e+00 1.06602570e+00 1.01679963e+00]\n",
      " [7.86127035e-01 2.85927021e-01 1.09650830e+00]\n",
      " [3.61505724e+00 6.95432351e-01 9.89409250e-01]\n",
      " [1.97718826e+00 4.28813228e+00 1.21667120e+00]\n",
      " [5.97770800e-01 5.98952865e-01 1.04379215e+00]\n",
      " [1.17001923e+00 2.92880298e+00 1.16765955e+00]\n",
      " [6.79839809e+00 1.67592651e+01 1.20498436e+00]\n",
      " [6.26188897e-01 2.23865405e-01 1.05920984e+00]\n",
      " [3.43324974e+00 9.66417033e-02 1.22466309e+00]\n",
      " [8.25695280e-01 1.95585181e-01 1.09804432e+00]\n",
      " [6.39387736e+00 2.81005627e+01 1.22232425e+00]\n",
      " [2.60243318e+00 4.24420757e+00 1.22468617e+00]\n",
      " [1.62096524e+01 1.22703872e-02 1.19279254e+00]\n",
      " [5.53107179e+00 2.72667884e+01 1.22469594e+00]\n",
      " [2.03405667e-01 8.68195107e-01 5.63069549e-01]\n",
      " [3.59588408e+00 1.03269341e+01 1.22053388e+00]\n",
      " [4.00173982e+01 1.22227318e-02 1.10321198e+00]\n",
      " [1.85132912e+00 1.88355751e+00 1.22256373e+00]\n",
      " [1.30001396e+00 2.29820614e-01 1.17147074e+00]\n",
      " [5.14274987e+00 1.79219918e+01 1.22266141e+00]\n",
      " [7.46040154e+00 4.06663972e-02 1.20602392e+00]\n",
      " [4.16075589e+00 7.91835073e-02 1.22402360e+00]\n",
      " [6.86744323e-01 2.76261595e+00 1.07434815e+00]\n",
      " [8.24871268e+00 1.07411087e+01 1.15043986e+00]\n",
      " [3.60718236e+00 2.39781333e+00 1.19872113e+00]\n",
      " [2.64020120e+00 5.45969674e+00 1.21605289e+00]\n",
      " [5.89030098e-01 1.98465629e+00 1.04280268e+00]\n",
      " [3.95780463e+00 2.86348304e+00 1.19403340e+00]\n",
      " [2.00591196e+00 1.61819518e+00 1.22465573e+00]\n",
      " [2.08334044e+00 5.87632732e-01 1.14886045e+00]\n",
      " [1.48565188e+01 1.29839408e+01 8.65502737e-01]\n",
      " [2.13660883e+00 3.85452789e+00 1.22208623e+00]\n",
      " [4.28856314e+00 3.96837247e+00 1.19532190e+00]\n",
      " [1.71333076e+00 1.56780250e+00 1.22021571e+00]\n",
      " [3.59763058e+00 4.37997531e+00 1.21241680e+00]\n",
      " [6.97993463e+00 2.31154060e+01 1.20855061e+00]\n",
      " [6.68778584e+00 1.35451835e+00 9.88861584e-01]\n",
      " [7.20079958e+00 3.22714905e-01 1.13368630e+00]\n",
      " [1.36769663e+00 7.80535216e-01 1.20277285e+00]\n",
      " [4.08247592e+00 3.91024979e-01 1.11967464e+00]\n",
      " [2.77135046e+00 1.90855586e+00 1.21575901e+00]\n",
      " [1.05954374e+01 8.73134250e+00 1.13131051e+00]\n",
      " [3.45806976e+00 1.61984174e+00 1.19624432e+00]\n",
      " [4.10991805e+00 1.67674519e+00 1.17946197e+00]\n",
      " [4.94575344e+00 2.91408227e-01 8.97292952e-01]\n",
      " [2.32799713e+00 4.11492939e+00 1.22396295e+00]\n",
      " [1.91282512e+00 6.35136569e+00 1.20433159e+00]\n",
      " [1.72200950e+00 7.71322247e-01 1.22121352e+00]\n",
      " [5.27032722e+00 1.12463148e-01 1.20338939e+00]\n",
      " [3.71848918e+00 1.72044151e+01 1.22179027e+00]\n",
      " [4.61572388e+00 1.58057340e+01 1.22391560e+00]\n",
      " [1.08311482e+01 3.15533573e-01 9.48168250e-01]\n",
      " [4.65393499e+00 2.36141937e-01 1.14814519e+00]\n",
      " [3.72753754e+00 2.54580655e+00 1.12869044e+00]\n",
      " [4.53300079e+00 1.53555772e+01 1.22401248e+00]\n",
      " [9.89770673e+00 4.88328889e+00 1.11624427e+00]\n",
      " [2.59382260e+00 2.63708998e-01 1.19900228e+00]\n",
      " [4.13054902e+01 1.07906425e-02 8.80912407e-01]\n",
      " [3.41699579e+00 3.01492757e-01 1.16172360e+00]\n",
      " [2.68541601e+00 1.75677381e+00 1.21687250e+00]\n",
      " [6.09373992e-01 1.10952789e+00 1.04523634e+00]\n",
      " [2.29275309e+00 1.65276405e+00 1.22331572e+00]\n",
      " [7.41825751e-01 2.47024398e-01 1.08523902e+00]\n",
      " [6.42532018e-01 6.45190180e-01 1.05885790e+00]\n",
      " [7.48868929e-01 2.60589182e-01 1.08733274e+00]\n",
      " [1.05567044e+00 4.64657194e-01 1.15754569e+00]\n",
      " [2.56108566e+00 4.15440798e+00 1.22472552e+00]\n",
      " [1.08248991e+01 9.21335649e-02 1.13850112e+00]\n",
      " [1.94991846e+00 1.18022089e+00 1.22463130e+00]\n",
      " [1.49933051e+00 1.24795367e-01 1.16763252e+00]\n",
      " [2.24154645e+00 4.03543318e-01 1.18012303e+00]\n",
      " [4.48040041e+00 3.17503871e-01 1.18428435e+00]\n",
      " [5.57935695e+00 1.99978320e+00 1.07099596e+00]\n",
      " [4.71950018e+00 2.40505324e+00 1.10010937e+00]\n",
      " [3.98300501e+00 3.65165194e+00 1.19974828e+00]\n",
      " [2.09924729e+00 1.28138255e-01 1.20628744e+00]\n",
      " [7.58325682e+00 2.09730388e+00 1.05464725e+00]\n",
      " [1.17387231e+01 7.99446215e+00 1.11761415e+00]\n",
      " [1.25710254e+00 6.37522252e-01 1.19029297e+00]\n",
      " [9.94505408e+00 2.70282210e-01 1.10746829e+00]\n",
      " [3.79749552e+00 1.00031347e+01 1.21719547e+00]\n",
      " [1.29608286e+00 1.40807129e-01 1.15305648e+00]\n",
      " [3.99989572e+00 4.53709424e+00 1.16969075e+00]\n",
      " [1.62113880e+01 3.39786454e+01 1.15081371e+00]\n",
      " [4.23670877e+00 1.38711293e+01 1.22436435e+00]\n",
      " [2.85828780e+00 2.75474551e+00 9.06021040e-01]\n",
      " [2.05761388e+00 5.53220988e+00 1.21407145e+00]\n",
      " [9.00064209e-01 3.24289711e+00 1.12113737e+00]\n",
      " [2.09996403e-01 1.22743679e+00 8.50318947e-01]\n",
      " [1.35711673e+02 2.35741234e+02 9.42773228e-01]\n",
      " [1.46966822e+00 6.18494117e-01 1.20856333e+00]\n",
      " [1.47572894e+00 1.52800754e-01 1.17375404e+00]\n",
      " [6.20167599e-01 1.27005143e+00 1.04978513e+00]\n",
      " [5.01130999e+00 8.08011418e-02 1.21677620e+00]\n",
      " [1.85495911e+00 4.74964446e+00 1.20974676e+00]\n",
      " [1.24396145e+00 2.27966963e-01 1.16486742e+00]\n",
      " [2.29905726e+00 3.73964441e+00 1.22423812e+00]\n",
      " [7.35686501e-02 1.66002897e+00 7.01482339e-01]\n",
      " [1.27197789e+01 5.88640058e-02 1.13202727e+00]\n",
      " [1.91955857e+00 2.38134762e-01 1.21511941e+00]\n",
      " [3.03407308e+00 2.75874237e+00 1.15834024e+00]\n",
      " [2.35345856e+00 3.10923998e+00 1.22473279e+00]\n",
      " [4.71306220e+00 6.07997802e+00 1.20016733e+00]\n",
      " [2.47099935e+00 2.21604492e+00 1.22249811e+00]\n",
      " [9.30512908e-01 4.83579561e-01 1.13502741e+00]\n",
      " [9.99188143e+00 3.69639651e-02 1.18414239e+00]\n",
      " [1.43253451e-01 4.06140707e-01 8.73645235e-01]\n",
      " [1.26062104e+00 3.09208462e-01 1.17620089e+00]\n",
      " [8.23897115e+00 9.44318112e-02 1.14967958e+00]\n",
      " [5.42553624e+00 6.56310550e-01 1.14857183e+00]\n",
      " [7.97489280e+00 3.92163588e+01 1.21994894e+00]\n",
      " [3.26060110e+00 3.38611034e+00 1.16844569e+00]\n",
      " [1.58463351e+00 6.93653599e-01 1.21585948e+00]\n",
      " [1.34907650e+01 1.99549115e-01 1.06511386e+00]\n",
      " [1.70179251e+01 1.50412073e+02 1.21385109e+00]\n",
      " [2.22173674e+00 3.68274322e+00 1.22364919e+00]\n",
      " [2.45448614e+00 9.07723235e-01 1.21953960e+00]\n",
      " [3.45959123e+00 8.06685059e+00 1.22402128e+00]\n",
      " [2.20265400e+00 1.50069153e+00 1.22398780e+00]\n",
      " [1.03437158e+00 2.04899985e+00 1.15481142e+00]\n",
      " [4.07218185e-02 8.18304839e-01 7.41868763e-01]\n",
      " [6.96887506e+00 1.34070411e-01 1.14511087e+00]\n",
      " [1.99534229e+00 1.08017038e-01 1.21682059e+00]\n",
      " [4.85266204e+00 5.35180974e-02 1.22194358e+00]\n",
      " [5.09485110e+00 1.31399196e-01 1.17980758e+00]\n",
      " [1.24547584e+01 4.22566322e+01 1.18553804e+00]\n",
      " [6.27233177e-01 2.42577321e+00 1.05710938e+00]\n",
      " [2.09436909e+00 4.42434094e+00 1.21943184e+00]\n",
      " [1.04264495e+00 2.24393666e-01 1.13747874e+00]\n",
      " [1.76045853e+00 3.31439960e-01 1.21505178e+00]\n",
      " [7.26961045e-01 1.90544176e+00 1.08589670e+00]\n",
      " [5.37710967e+00 1.92759631e+00 1.07072256e+00]\n",
      " [2.52836473e+00 3.18183896e-01 1.22398509e+00]\n",
      " [1.45828766e+00 2.09977023e-01 1.18387361e+00]\n",
      " [3.06801333e+00 1.52511529e-01 1.22457200e+00]\n",
      " [3.87630537e+00 3.69852679e+00 1.20246941e+00]\n",
      " [3.24017959e+00 6.70777053e+00 1.22392405e+00]\n",
      " [5.64293767e+00 5.76167778e+00 1.18080532e+00]\n",
      " [4.24745612e+00 6.87727093e+00 1.19151060e+00]\n",
      " [4.12275751e-01 3.53806503e-01 9.90755184e-01]\n",
      " [3.11657910e+00 1.48547069e+00 1.20462449e+00]\n",
      " [2.18911791e+00 1.40159467e+00 1.22398285e+00]\n",
      " [2.67377312e-01 4.34458376e-01 9.22540787e-01]\n",
      " [1.12718583e+00 2.29572482e-01 1.15029955e+00]\n",
      " [9.14141172e+00 1.17744786e+00 9.97104751e-01]\n",
      " [6.61041277e+00 2.73226745e-01 1.10179845e+00]\n",
      " [1.86124931e+01 2.37212146e+01 1.11232031e+00]\n",
      " [3.41687079e+00 1.36941698e-01 1.21211648e+00]\n",
      " [6.25840507e-01 5.04119500e-01 1.05505821e+00]\n",
      " [1.38890588e+00 1.59729857e-01 1.21223341e+00]\n",
      " [6.30593946e+00 4.60076719e-02 1.21795047e+00]\n",
      " [5.13014472e+00 5.63767833e-02 1.22259650e+00]\n",
      " [3.37211429e+00 7.90448935e-01 1.00761269e+00]\n",
      " [2.38041269e+00 6.82544479e-01 1.22165267e+00]\n",
      " [2.93296355e+00 1.59517548e+00 1.21011371e+00]\n",
      " [1.11901766e+00 2.62127051e+00 1.16327504e+00]\n",
      " [3.20766126e+00 3.25192840e+00 1.21405335e+00]\n",
      " [2.78197870e+00 2.55463552e+00 1.21878239e+00]\n",
      " [1.76571053e+00 3.01462221e-01 1.21734400e+00]\n",
      " [2.32353494e+00 5.68952365e-01 1.22317729e+00]\n",
      " [5.28344250e+00 4.64822293e-02 1.22168416e+00]\n",
      " [9.24894830e+00 2.61743040e-02 1.21073681e+00]\n",
      " [6.71486766e+00 1.93095448e+00 8.25246870e-01]\n",
      " [6.84868506e+00 1.80354882e+00 1.05046812e+00]\n",
      " [6.90209634e+00 2.62012272e+01 1.21775723e+00]\n",
      " [2.54260688e+00 1.77191375e-01 1.21898846e+00]\n",
      " [4.67176522e+00 8.59170142e-02 1.20997719e+00]\n",
      " [3.65213244e+00 3.91841810e+00 1.16815246e+00]\n",
      " [4.58596198e+00 2.48098957e-01 1.14587564e+00]\n",
      " [1.49171221e+00 3.08595337e-01 1.19806917e+00]\n",
      " [1.29145219e+01 8.13774115e+00 1.09101546e+00]\n",
      " [3.59627173e+00 5.39541890e+00 1.19230224e+00]\n",
      " [3.67036227e+00 2.26612981e+00 1.19599326e+00]\n",
      " [2.32489700e+00 8.52495646e-01 1.22195456e+00]\n",
      " [7.45900223e+00 1.18080160e+01 1.16714211e+00]\n",
      " [2.00366690e-01 4.45145584e-01 8.90396182e-01]\n",
      " [1.23674828e+00 2.79612360e+00 1.17727562e+00]\n",
      " [3.25707151e+00 1.38308748e-01 1.22430739e+00]\n",
      " [2.16101396e+00 7.11054527e+00 1.21139526e+00]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "\n",
    "X = []\n",
    "# Define a function to extract ROIs around microbleed locations\n",
    "def extract_roi(swi_data, coordinates, roi_size):\n",
    "    rois = []\n",
    "    for coord in coordinates:\n",
    "        x, y, z = coord\n",
    "        # Ensure the ROI stays within the image bounds\n",
    "        x_start = max(0, x - roi_size // 2)\n",
    "        x_end = min(swi_data.shape[0], x + (roi_size + 1) // 2)\n",
    "        y_start = max(0, y - roi_size // 2)\n",
    "        y_end = min(swi_data.shape[1], y + (roi_size + 1) // 2)\n",
    "        z_start = max(0, z - roi_size // 2)\n",
    "        z_end = min(swi_data.shape[2], z + (roi_size + 1) // 2)\n",
    "        \n",
    "        # Extract the ROI from the image data\n",
    "        roi = swi_data[x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "        rois.append(roi)\n",
    "    return rois\n",
    "\n",
    "# Define a function to compute Hessian matrix eigenvalues\n",
    "def compute_hessian_eigenvalues(roi):\n",
    "    # Apply Gaussian filter to the ROI for smoothing\n",
    "    smoothed_roi = gaussian_filter(roi, sigma=1)\n",
    "    \n",
    "    # Compute gradients along x, y, and z directions using Sobel filters\n",
    "    gradient_x = ndimage.sobel(smoothed_roi, axis=0)\n",
    "    gradient_y = ndimage.sobel(smoothed_roi, axis=1)\n",
    "    gradient_z = ndimage.sobel(smoothed_roi, axis=2)\n",
    "    \n",
    "    # Compute second derivatives along x, y, and z directions\n",
    "    dxx = ndimage.sobel(gradient_x, axis=0)\n",
    "    dyy = ndimage.sobel(gradient_y, axis=1)\n",
    "    dzz = ndimage.sobel(gradient_z, axis=2)\n",
    "    dxy = ndimage.sobel(gradient_x, axis=1)\n",
    "    dxz = ndimage.sobel(gradient_x, axis=2)\n",
    "    dyz = ndimage.sobel(gradient_y, axis=2)\n",
    "    \n",
    "    # Construct the Hessian matrix\n",
    "    Hessian_matrix = np.array([\n",
    "        [dxx.mean(), dxy.mean(), dxz.mean()],\n",
    "        [dxy.mean(), dyy.mean(), dyz.mean()],\n",
    "        [dxz.mean(), dyz.mean(), dzz.mean()]\n",
    "    ])\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors of the Hessian matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(Hessian_matrix)\n",
    "    \n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "# Define a function to compute Hessian shape features\n",
    "def compute_hessian_shape_features(eigenvalues):\n",
    "    if len(eigenvalues) != 3:\n",
    "        # If the number of eigenvalues is not 3, return default values or handle the case accordingly\n",
    "        print(\"Invalid number of eigenvalues for computing features\")\n",
    "        return 0, 0, 0  # Return default values or handle differently if needed\n",
    "    \n",
    "    # Sphericalness feature\n",
    "    f_sphere = abs(eigenvalues[0]) / np.sqrt(abs(eigenvalues[1] * eigenvalues[2]))\n",
    "    \n",
    "    # Largest cross-section feature\n",
    "    f_lc = abs(eigenvalues[1]) / abs(eigenvalues[2])\n",
    "    \n",
    "    # Fractional anisotropy feature\n",
    "    f_fa = np.sqrt(0.5) * np.sqrt((eigenvalues[0] - eigenvalues[1])**2 + \n",
    "                                  (eigenvalues[1] - eigenvalues[2])**2 + \n",
    "                                  (eigenvalues[0] - eigenvalues[2])**2) / np.sqrt((eigenvalues[0]**2 + eigenvalues[1]**2 + eigenvalues[2]**2))\n",
    "    \n",
    "    return f_sphere, f_lc, f_fa\n",
    "\n",
    "# Load the Excel file containing microbleed coordinates\n",
    "excel_file = 'NoCMB.xlsx'  # Replace with your Excel file path\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Path to the folder containing the NIFTI images\n",
    "folder_path = 'noncmb'  # Replace 'path_to_rCMB_folder' with your folder path\n",
    "\n",
    "# Iterate through rows to load NIFTI files and extract microbleed features\n",
    "for index, row in df.iterrows():\n",
    "    nifti_filename = row['NIFTI']  # Assuming 'NIFTI' is the column name containing the NIFTI file names\n",
    "    nifti_path = os.path.join(folder_path, nifti_filename)\n",
    "\n",
    "    # Check if the NIFTI file exists in the folder\n",
    "    if os.path.exists(nifti_path):\n",
    "        swi_img = nib.load(nifti_path)\n",
    "        swi_data = swi_img.get_fdata()\n",
    "\n",
    "        # Extract microbleed coordinates for the current NIFTI file\n",
    "        microbleed_coordinates = []\n",
    "        for i in range(1, len(row), 3):\n",
    "            try:\n",
    "                if pd.notnull(row[i]) and pd.notnull(row[i+1]) and pd.notnull(row[i+2]):\n",
    "                    x = int(row[i])\n",
    "                    y = int(row[i+1])\n",
    "                    z = int(row[i+2])\n",
    "                    microbleed_coordinates.append((x, y, z))\n",
    "            except (ValueError, TypeError):\n",
    "                pass  # Skip non-numeric or empty values\n",
    "\n",
    "        # Process microbleed coordinates for the current NIFTI file\n",
    "        #print(f\"NIFTI Filename: {nifti_filename}\")\n",
    "        #print(f\"Microbleed Coordinates: {microbleed_coordinates}\")\n",
    "        #print(f\"SWI Image Shape: {swi_data.shape}\")\n",
    "        \n",
    "        # Define the size of the ROI around each microbleed\n",
    "        roi_size = 10  # Adjust this according to your desired size\n",
    "\n",
    "        # Extract ROIs around microbleed locations\n",
    "        microbleed_rois = extract_roi(swi_data, microbleed_coordinates, roi_size)\n",
    "\n",
    "        # Compute Hessian matrix and eigenvalues for each ROI\n",
    "        eigenvalues_list = []\n",
    "        for roi in microbleed_rois:\n",
    "            eigenvalues = compute_hessian_eigenvalues(roi)\n",
    "            eigenvalues_list.append(eigenvalues)\n",
    "\n",
    "        # Compute Hessian shape features for each microbleed\n",
    "        hessian_shape_features_microbleed = []\n",
    "        for i, eigenvals_tuple in enumerate(eigenvalues_list):\n",
    "            eigenvals = eigenvals_tuple[0]  # Unpack the nested structure\n",
    "            if len(eigenvals) != 3:\n",
    "                # Print the invalid eigenvalues and their count for inspection\n",
    "                print(f\"Invalid eigenvalues at index {i+1}: {eigenvals} (Count: {len(eigenvals)})\")\n",
    "                continue\n",
    "            \n",
    "            f_sphere, f_lc, f_fa = compute_hessian_shape_features(eigenvals)\n",
    "            hessian_shape_features_microbleed.append((f_sphere, f_lc, f_fa))\n",
    "\n",
    "        # Append the computed features to the main feature list (X)\n",
    "        X.extend(hessian_shape_features_microbleed)\n",
    "\n",
    "# Convert the list of microbleed features to a NumPy array\n",
    "X0 = np.array(X)\n",
    "\n",
    "# Display the shape of the resulting feature array\n",
    "print(f\"Shape of X (non microbleed features): {X0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y0 (labels): (300,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Assuming X contains the microbleed features\n",
    "\n",
    "# Determine the number of microbleeds in X\n",
    "num_microbleeds = X0.shape[0]\n",
    "\n",
    "# Set the labels for microbleeds as 1\n",
    "Y0 = np.zeros(num_microbleeds)\n",
    "\n",
    "# Display the shape of the label array\n",
    "print(f\"Shape of Y0 (labels): {Y0.shape}\")\n",
    "\n",
    "# Display a few labels to confirm\n",
    "print(Y0)  # Displaying the first 10 labels as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446, 3)\n",
      "(446,)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((X1,X0))\n",
    "print(X.shape)\n",
    "\n",
    "# Create corresponding labels 'y' (1 for microbleeds, 0 for non-microbleeds)\n",
    "Y = np.hstack((Y1,Y0))\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Test Data: [1.32767805 0.05950164 1.15259539]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 2:\n",
      "Test Data: [3.51647468 0.06874615 1.22237274]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 3:\n",
      "Test Data: [1.24134782 0.24095702 1.16638347]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 4:\n",
      "Test Data: [7.27337142 2.36041728 0.94989579]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 5:\n",
      "Test Data: [7.42396307 5.91418701 1.12315262]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 6:\n",
      "Test Data: [0.99059464 2.32444948 1.14477086]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 7:\n",
      "Test Data: [ 4.61108356 14.58206085  1.21841045]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 8:\n",
      "Test Data: [1.53889507 0.22882647 1.19326105]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 9:\n",
      "Test Data: [3.42385586 0.31585564 1.20891033]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 10:\n",
      "Test Data: [4.4966617  0.0522553  1.22410769]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 11:\n",
      "Test Data: [1.67778226 0.27429437 1.20732978]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 12:\n",
      "Test Data: [4.72397652 2.08363247 0.9474458 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 13:\n",
      "Test Data: [0.28684699 0.62199872 0.90699359]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 14:\n",
      "Test Data: [3.75205075 3.78779632 1.16258527]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 15:\n",
      "Test Data: [7.34856318 1.33622543 0.98980795]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 16:\n",
      "Test Data: [2.42714012 0.39872539 1.22370135]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 17:\n",
      "Test Data: [0.29669687 2.74547503 0.94710755]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 18:\n",
      "Test Data: [2.33587599 0.16337733 1.2196201 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 19:\n",
      "Test Data: [2.83685812 0.36466158 0.90668447]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 20:\n",
      "Test Data: [9.12516182 0.13702058 1.1160502 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 21:\n",
      "Test Data: [10.55091972  0.72017281  0.98901199]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 22:\n",
      "Test Data: [ 5.0983837  16.93844735  1.21759047]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 23:\n",
      "Test Data: [2.68877163 2.08575314 1.21837497]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 24:\n",
      "Test Data: [1.30987328 2.50911424 1.18799764]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 25:\n",
      "Test Data: [ 7.92073377 17.45164935  1.19310752]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 26:\n",
      "Test Data: [ 11.32181465 106.13094196   1.2236577 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 27:\n",
      "Test Data: [0.360442   0.2591607  0.98714833]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 28:\n",
      "Test Data: [6.73332467 0.33460327 1.1396069 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 29:\n",
      "Test Data: [2.95025441 0.23758036 1.22211723]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 30:\n",
      "Test Data: [3.57923166 6.54477754 1.22058401]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 31:\n",
      "Test Data: [4.01269264 0.27710458 1.19876065]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 32:\n",
      "Test Data: [ 5.56450545 13.35562615  1.21237078]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 33:\n",
      "Test Data: [3.93442759 2.42965701 1.19076796]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 34:\n",
      "Test Data: [0.91651264 1.85276468 1.13352285]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 35:\n",
      "Test Data: [1.34994121 0.30479344 1.22443437]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 36:\n",
      "Test Data: [1.7741714  0.50826209 1.22050613]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 37:\n",
      "Test Data: [4.01998786 0.12249239 1.20548576]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 38:\n",
      "Test Data: [6.28787691 0.47737101 0.95435682]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 39:\n",
      "Test Data: [3.44126438 0.11778434 1.21715442]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 40:\n",
      "Test Data: [2.54901894 6.48328474 1.22237951]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 41:\n",
      "Test Data: [3.50056895 0.11903838 1.21589705]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 42:\n",
      "Test Data: [4.90214452 0.17375145 1.16520777]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 43:\n",
      "Test Data: [3.98126702 0.2301357  0.67174142]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 44:\n",
      "Test Data: [6.45574226 0.18302037 1.16451866]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 45:\n",
      "Test Data: [1.77250231 0.05172347 1.14868341]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 46:\n",
      "Test Data: [5.25317222 2.35418875 1.1598063 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 47:\n",
      "Test Data: [13.09457147  0.04755697  1.14956316]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 48:\n",
      "Test Data: [2.74621443 2.40049797 1.15593071]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 49:\n",
      "Test Data: [3.89400426 0.23121144 1.1689445 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 50:\n",
      "Test Data: [5.6004845  8.04761982 1.19435307]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 51:\n",
      "Test Data: [10.49336334  0.04670513  1.17417303]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 52:\n",
      "Test Data: [2.14913657 0.1481952  1.21236729]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 53:\n",
      "Test Data: [0.70691364 0.46554458 1.080051  ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 54:\n",
      "Test Data: [0.78917894 0.40486333 1.10102962]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 55:\n",
      "Test Data: [0.34049441 0.56397622 0.93883641]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 56:\n",
      "Test Data: [3.99705052 0.23893531 1.20315438]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 57:\n",
      "Test Data: [ 5.79310665 12.61201925  1.2076683 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 58:\n",
      "Test Data: [3.82802026 0.9029348  1.0181079 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 59:\n",
      "Test Data: [4.15613723 7.35189927 1.21516505]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 60:\n",
      "Test Data: [2.36091906 2.19683598 1.22371113]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 61:\n",
      "Test Data: [2.58090667 0.08892237 1.2221898 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 62:\n",
      "Test Data: [ 7.97664786 21.17883076  1.19330467]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 63:\n",
      "Test Data: [ 3.31637014 16.68501508  1.2171687 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 64:\n",
      "Test Data: [ 3.33717642 10.11137561  1.22450872]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 65:\n",
      "Test Data: [2.51701814 0.07606423 1.20456941]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 66:\n",
      "Test Data: [4.40316821 8.97571289 1.20282015]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 67:\n",
      "Test Data: [1.06565561 1.35170048 1.16536445]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 68:\n",
      "Test Data: [1.22454136 0.03863567 1.09521835]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 69:\n",
      "Test Data: [1.48077431 4.64315929 1.18665574]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 70:\n",
      "Test Data: [1.28778157 0.88546382 1.19592327]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 71:\n",
      "Test Data: [4.07502487 0.24639918 1.15917245]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 72:\n",
      "Test Data: [2.00502896 1.60506801 1.22465921]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 73:\n",
      "Test Data: [4.26049442 4.04570677 1.15411755]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 74:\n",
      "Test Data: [2.23009459 6.08522338 1.21722269]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 75:\n",
      "Test Data: [4.31046438 0.15235835 1.2097674 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 76:\n",
      "Test Data: [1.78029336 5.43713458 1.20222118]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 77:\n",
      "Test Data: [1.64515579 2.84495289 1.21074703]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 78:\n",
      "Test Data: [0.05603826 0.36092867 0.84940348]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 79:\n",
      "Test Data: [17.9322151   0.02708313  1.13951331]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 80:\n",
      "Test Data: [1.99914089 1.33451792 1.22472904]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 81:\n",
      "Test Data: [1.63576142 2.00129841 1.21540381]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 82:\n",
      "Test Data: [1.49983024 3.81209621 1.19432101]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 83:\n",
      "Test Data: [0.78376193 2.39564896 1.09996398]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 84:\n",
      "Test Data: [5.93404727 0.12453219 1.18868523]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 85:\n",
      "Test Data: [1.42178391 0.37282812 1.19695871]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 86:\n",
      "Test Data: [3.10825151 0.69524377 1.08678487]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 87:\n",
      "Test Data: [0.95949157 0.38487553 1.13688381]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 88:\n",
      "Test Data: [1.8824982  0.24430335 1.21425808]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 89:\n",
      "Test Data: [2.56999123 2.21719182 1.22105005]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 90:\n",
      "Test Data: [2.38566591 1.68801704 1.2221732 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 91:\n",
      "Test Data: [3.07968701 3.38433939 1.21720061]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 92:\n",
      "Test Data: [1.25219679 3.90717494 1.16958603]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 93:\n",
      "Test Data: [1.22130454 2.4403917  1.17863169]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 94:\n",
      "Test Data: [3.41513117 5.26950037 1.19556265]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 95:\n",
      "Test Data: [0.48509909 2.39277994 1.01044816]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 96:\n",
      "Test Data: [1.63920851 3.25496866 1.20773024]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 97:\n",
      "Test Data: [4.26353845 0.06750689 1.22193205]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 98:\n",
      "Test Data: [5.60935679 0.06761681 1.21474073]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 99:\n",
      "Test Data: [1.50216068 3.20616376 1.19912352]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 100:\n",
      "Test Data: [2.64835995 0.94504956 1.06183967]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 101:\n",
      "Test Data: [10.11413149 17.24270474  1.1572217 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 102:\n",
      "Test Data: [6.55596004 0.91240939 1.01763957]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 103:\n",
      "Test Data: [22.97087994 61.41916481  1.14119002]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 104:\n",
      "Test Data: [ 6.54592817 17.94795817  1.21023875]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 105:\n",
      "Test Data: [7.05799354 0.37626594 1.07457904]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 106:\n",
      "Test Data: [1.49205854 1.24704399 1.21175849]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 107:\n",
      "Test Data: [3.44626953 0.313767   1.20855038]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 108:\n",
      "Test Data: [5.36219064 3.93504304 1.12747334]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 109:\n",
      "Test Data: [2.01461532 5.91875284 1.21083083]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 110:\n",
      "Test Data: [5.72128099 2.81019772 1.09542251]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 111:\n",
      "Test Data: [71.35492631  0.08254872  1.02590548]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 112:\n",
      "Test Data: [2.5722853  0.30647723 1.22384102]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 113:\n",
      "Test Data: [5.20283126 0.68459641 1.04981726]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 114:\n",
      "Test Data: [ 6.45775427 10.54495396  1.19143805]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 115:\n",
      "Test Data: [ 8.36557334 16.62699166  1.18562813]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 116:\n",
      "Test Data: [3.02164378 0.11649035 1.22259634]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 117:\n",
      "Test Data: [2.03824871 0.95477984 1.08524129]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 118:\n",
      "Test Data: [1.01940297 0.36345176 1.1464159 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 119:\n",
      "Test Data: [1.99366195 0.13989066 1.20444248]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 120:\n",
      "Test Data: [ 9.40274217 34.04163509  1.20121247]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 121:\n",
      "Test Data: [1.26578423 0.16464473 1.2082649 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 122:\n",
      "Test Data: [2.87309009 4.49138714 1.20086727]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 123:\n",
      "Test Data: [3.36395295 5.429417   1.2203284 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 124:\n",
      "Test Data: [1.42364885 2.77538522 1.19634598]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 125:\n",
      "Test Data: [0.69358912 0.29884874 1.07565289]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 126:\n",
      "Test Data: [0.5594347  0.22497639 1.04367941]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 127:\n",
      "Test Data: [ 9.01136979 18.43172597  1.17347945]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 128:\n",
      "Test Data: [1.67862828 0.34693655 1.21219658]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 129:\n",
      "Test Data: [6.63910246 5.73348981 1.13250632]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 130:\n",
      "Test Data: [2.76115184 0.05440024 1.21157775]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 131:\n",
      "Test Data: [5.41056246 2.30128064 0.9414078 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 132:\n",
      "Test Data: [1.60943789 0.21952077 1.19708094]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 133:\n",
      "Test Data: [5.42391217 0.29920965 1.11374856]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 134:\n",
      "Test Data: [6.00366182 2.8323875  0.92674917]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 135:\n",
      "Test Data: [4.65323448 0.0759233  1.22146381]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 136:\n",
      "Test Data: [1.88578407 0.75416523 1.22409295]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 137:\n",
      "Test Data: [1.7048722  1.50508215 1.22016768]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 138:\n",
      "Test Data: [1.62746531 1.79649227 1.21611837]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 139:\n",
      "Test Data: [6.28812956 3.04847456 0.92271278]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 140:\n",
      "Test Data: [ 4.49963724 16.03393304  1.22162243]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 141:\n",
      "Test Data: [4.69206601 9.9073893  1.21511426]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 142:\n",
      "Test Data: [3.28467872 1.37326277 1.07644749]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 143:\n",
      "Test Data: [3.93503032 3.69160729 1.15537334]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 144:\n",
      "Test Data: [0.17538124 0.60927088 0.84862013]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 145:\n",
      "Test Data: [0.59625674 1.99179106 1.04529777]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 146:\n",
      "Test Data: [8.23829725 0.09313318 1.1505536 ]\n",
      "Actual Label: 1.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 147:\n",
      "Test Data: [6.36109412 0.17848556 1.16708038]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 148:\n",
      "Test Data: [2.18786517 0.41516503 1.22474295]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 149:\n",
      "Test Data: [1.77420719 0.06449627 1.15926498]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 150:\n",
      "Test Data: [6.1228267  4.42516792 1.12263418]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 151:\n",
      "Test Data: [3.54654334 0.2553958  1.21091053]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 152:\n",
      "Test Data: [32.04223751  0.04650792  0.93048684]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 153:\n",
      "Test Data: [1.13090149 0.4501724  1.1685896 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 154:\n",
      "Test Data: [15.34202038 13.13995814  1.10032242]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 155:\n",
      "Test Data: [1.6291281  5.10285691 1.1948566 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 156:\n",
      "Test Data: [0.10263724 0.50115133 1.19487107]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 157:\n",
      "Test Data: [3.18729385 0.19600362 1.19965543]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 158:\n",
      "Test Data: [4.38224643 2.17180186 0.72268603]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 159:\n",
      "Test Data: [1.34485269 2.44519517 1.19205404]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 160:\n",
      "Test Data: [1.36619914 2.66923884 1.19214418]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 161:\n",
      "Test Data: [5.28601971 7.77699313 1.19841611]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 162:\n",
      "Test Data: [1.36477608 0.50664434 1.19787667]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 163:\n",
      "Test Data: [2.10604068 0.82598928 1.22444871]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 164:\n",
      "Test Data: [1.39458267 1.07980262 1.10725211]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 165:\n",
      "Test Data: [ 4.14219438 17.34093704  1.22433874]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 166:\n",
      "Test Data: [3.64922051 1.75394073 1.19215173]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 167:\n",
      "Test Data: [7.34836621 0.08895054 1.18126342]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 168:\n",
      "Test Data: [2.7885988  2.16963018 1.21676669]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 169:\n",
      "Test Data: [1.50252327 0.66773384 1.21129323]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 170:\n",
      "Test Data: [7.16026322 4.68725236 1.1112639 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 171:\n",
      "Test Data: [4.32796826 2.59737549 1.18273104]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 172:\n",
      "Test Data: [ 4.41357537 15.23067716  1.22436407]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 173:\n",
      "Test Data: [3.87935341 0.24773191 1.16404042]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 174:\n",
      "Test Data: [0.96134487 0.44605936 1.13991258]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 175:\n",
      "Test Data: [5.97130673 0.98839193 1.01410416]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 176:\n",
      "Test Data: [8.1771273  6.04276963 1.11500764]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 177:\n",
      "Test Data: [11.10212845  7.06315464  1.11826565]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 178:\n",
      "Test Data: [16.01300308  0.02759216  1.15051904]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 179:\n",
      "Test Data: [2.55478191 4.60197149 1.22468725]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 180:\n",
      "Test Data: [6.89061191 5.9651044  1.16097944]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 181:\n",
      "Test Data: [ 8.43133195 11.09299295  1.16616746]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 182:\n",
      "Test Data: [4.058998   1.13673097 1.04030163]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 183:\n",
      "Test Data: [ 5.65641675 10.44506316  1.20308452]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 184:\n",
      "Test Data: [7.21228071 5.12445255 1.15016375]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 185:\n",
      "Test Data: [1.13552839 0.42738915 1.16818843]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 186:\n",
      "Test Data: [1.6152768  0.15306038 1.18514396]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 187:\n",
      "Test Data: [0.5336542  0.54598251 1.02165283]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 188:\n",
      "Test Data: [3.34474682 0.38135648 1.14305952]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 189:\n",
      "Test Data: [10.72527723 93.39882701  1.22384673]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 190:\n",
      "Test Data: [1.41228797 1.11085998 1.10116492]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 191:\n",
      "Test Data: [7.48719685 0.64949151 0.98043999]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 192:\n",
      "Test Data: [10.17794082  6.55194501  1.12391703]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 193:\n",
      "Test Data: [8.17939144 4.32785543 1.13099078]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 194:\n",
      "Test Data: [5.28867628 1.79971297 1.15368221]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 195:\n",
      "Test Data: [7.86256254 0.08171351 1.16368701]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 196:\n",
      "Test Data: [6.14948617 0.35078818 1.09028221]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 197:\n",
      "Test Data: [4.18420286 4.27570717 1.16037884]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 198:\n",
      "Test Data: [4.78854162 4.15423091 1.18598626]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 199:\n",
      "Test Data: [1.88098235 2.73226431 1.22036652]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 200:\n",
      "Test Data: [6.55756118 0.10598902 1.18530754]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 201:\n",
      "Test Data: [1.40412274 0.52612343 1.20179745]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 202:\n",
      "Test Data: [1.83150077 0.21885335 1.20963731]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 203:\n",
      "Test Data: [4.17351161 3.11456717 1.19106805]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 204:\n",
      "Test Data: [0.89386461 0.62458639 1.12999106]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 205:\n",
      "Test Data: [2.69764267 1.5538843  1.21564001]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 206:\n",
      "Test Data: [5.86004541 0.23220026 0.886318  ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 207:\n",
      "Test Data: [3.65081924 0.05829822 1.2211556 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 208:\n",
      "Test Data: [2.73427372 0.28458229 1.22281614]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 209:\n",
      "Test Data: [1.91280344 4.13227227 1.21519253]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 210:\n",
      "Test Data: [9.35689171 0.08961474 1.13935658]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 211:\n",
      "Test Data: [2.77902092 8.79571908 1.22137148]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 212:\n",
      "Test Data: [1.00169183 2.5299271  1.14512733]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 213:\n",
      "Test Data: [1.85594542 0.14110906 1.19773461]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 214:\n",
      "Test Data: [4.86570598 2.05630581 1.08390549]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 215:\n",
      "Test Data: [3.67849833 0.24897673 1.20879437]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 216:\n",
      "Test Data: [4.28195554 0.18185946 1.20519443]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 217:\n",
      "Test Data: [1.17704022 0.68132787 1.18127145]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 218:\n",
      "Test Data: [5.23670257 0.81576355 0.99884206]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 219:\n",
      "Test Data: [3.12420703 0.23171107 1.22017553]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 220:\n",
      "Test Data: [0.29057608 0.15788339 0.98827947]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 221:\n",
      "Test Data: [0.64361498 0.26461219 1.06330225]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 222:\n",
      "Test Data: [2.91664196 7.5077399  1.22429637]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 223:\n",
      "Test Data: [16.57800412  0.4883864   0.93225494]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 224:\n",
      "Test Data: [1.40246898 0.2521727  1.18480363]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 225:\n",
      "Test Data: [0.59000156 0.61360764 1.04072379]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 226:\n",
      "Test Data: [2.38156914 0.35423893 1.18533153]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 227:\n",
      "Test Data: [0.65616756 1.94698081 1.06463767]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 228:\n",
      "Test Data: [5.90804094 1.80598043 1.05920755]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 229:\n",
      "Test Data: [2.82399495 0.50210836 1.21503826]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 230:\n",
      "Test Data: [2.61614926 0.25529275 1.20032609]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 231:\n",
      "Test Data: [1.43736127 0.19502914 1.22063434]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 232:\n",
      "Test Data: [5.37814299 4.61651936 1.17763962]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 233:\n",
      "Test Data: [3.11007015 8.77269848 1.22435015]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 234:\n",
      "Test Data: [2.13369544 0.22233015 1.21956849]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 235:\n",
      "Test Data: [4.69504493 0.17483804 1.19849288]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 236:\n",
      "Test Data: [1.90665091 3.40504505 1.21830063]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 237:\n",
      "Test Data: [1.23995348 1.9803288  1.18499257]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 238:\n",
      "Test Data: [0.72297091 0.3385733  1.08343895]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 239:\n",
      "Test Data: [6.6217386  3.62437942 0.80136847]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 240:\n",
      "Test Data: [5.3906424  0.25572291 1.17166026]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 241:\n",
      "Test Data: [5.88550719 0.05327472 1.21253507]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 242:\n",
      "Test Data: [4.31250631 0.17190208 1.17940416]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 243:\n",
      "Test Data: [4.7257957  0.26057497 1.13878167]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 244:\n",
      "Test Data: [2.56717885 8.69498937 1.21784137]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 245:\n",
      "Test Data: [0.67664789 0.57248212 1.07064968]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 246:\n",
      "Test Data: [2.45097409 0.29562018 1.22464728]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 247:\n",
      "Test Data: [1.08337703 0.47212524 1.1623226 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 248:\n",
      "Test Data: [3.03808352 4.08894647 1.22064608]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 249:\n",
      "Test Data: [2.61335550e+01 4.27326662e-03 1.19799814e+00]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 250:\n",
      "Test Data: [1.28042818 0.56946744 1.19139578]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 251:\n",
      "Test Data: [4.45335871 0.56601523 1.1717928 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 252:\n",
      "Test Data: [8.08188046 0.48694217 1.1131267 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 253:\n",
      "Test Data: [1.34570106 0.25226192 1.17930247]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 254:\n",
      "Test Data: [4.37383974 1.15219555 1.16933681]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 255:\n",
      "Test Data: [15.14295171  0.02484155  1.16242888]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 256:\n",
      "Test Data: [2.02032599 2.11204286 0.95818397]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 257:\n",
      "Test Data: [2.86294111 7.73156069 1.22376721]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 258:\n",
      "Test Data: [6.46434879 0.58954297 1.13179154]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 259:\n",
      "Test Data: [1.68918688 4.25300068 1.20410275]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 260:\n",
      "Test Data: [1.42445808 2.93797571 1.19507342]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 261:\n",
      "Test Data: [2.17243371 3.03659626 1.22422118]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 262:\n",
      "Test Data: [2.68272482 0.45541655 1.14950721]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 263:\n",
      "Test Data: [2.36990674 4.74244247 1.2233673 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 264:\n",
      "Test Data: [ 4.24692374 18.71770352  1.22420971]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 265:\n",
      "Test Data: [3.52937208 0.5195205  1.10679824]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 266:\n",
      "Test Data: [ 6.09675556 25.67933601  1.21985152]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 267:\n",
      "Test Data: [9.70332339 0.03309456 1.19787507]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 268:\n",
      "Test Data: [6.27297746 1.0660257  1.01679963]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 269:\n",
      "Test Data: [0.78612703 0.28592702 1.0965083 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 270:\n",
      "Test Data: [3.61505724 0.69543235 0.98940925]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 271:\n",
      "Test Data: [1.97718826 4.28813228 1.2166712 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 272:\n",
      "Test Data: [0.5977708  0.59895287 1.04379215]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 273:\n",
      "Test Data: [1.17001923 2.92880298 1.16765955]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 274:\n",
      "Test Data: [ 6.79839809 16.75926512  1.20498436]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 275:\n",
      "Test Data: [0.6261889  0.22386541 1.05920984]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 276:\n",
      "Test Data: [3.43324974 0.0966417  1.22466309]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 277:\n",
      "Test Data: [0.82569528 0.19558518 1.09804432]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 278:\n",
      "Test Data: [ 6.39387736 28.10056272  1.22232425]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 279:\n",
      "Test Data: [2.60243318 4.24420757 1.22468617]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 280:\n",
      "Test Data: [1.62096524e+01 1.22703872e-02 1.19279254e+00]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 281:\n",
      "Test Data: [ 5.53107179 27.26678839  1.22469594]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 282:\n",
      "Test Data: [0.20340567 0.86819511 0.56306955]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 283:\n",
      "Test Data: [ 3.59588408 10.32693411  1.22053388]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 284:\n",
      "Test Data: [4.00173982e+01 1.22227318e-02 1.10321198e+00]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 285:\n",
      "Test Data: [1.85132912 1.88355751 1.22256373]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 286:\n",
      "Test Data: [1.30001396 0.22982061 1.17147074]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 287:\n",
      "Test Data: [ 5.14274987 17.92199176  1.22266141]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 288:\n",
      "Test Data: [7.46040154 0.0406664  1.20602392]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 289:\n",
      "Test Data: [4.16075589 0.07918351 1.2240236 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 290:\n",
      "Test Data: [0.68674432 2.76261595 1.07434815]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 291:\n",
      "Test Data: [ 8.24871268 10.74110868  1.15043986]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 292:\n",
      "Test Data: [3.60718236 2.39781333 1.19872113]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 293:\n",
      "Test Data: [2.6402012  5.45969674 1.21605289]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 294:\n",
      "Test Data: [0.5890301  1.98465629 1.04280268]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 295:\n",
      "Test Data: [3.95780463 2.86348304 1.1940334 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 296:\n",
      "Test Data: [2.00591196 1.61819518 1.22465573]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 297:\n",
      "Test Data: [2.08334044 0.58763273 1.14886045]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 298:\n",
      "Test Data: [14.85651882 12.98394076  0.86550274]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 299:\n",
      "Test Data: [2.13660883 3.85452789 1.22208623]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 300:\n",
      "Test Data: [4.28856314 3.96837247 1.1953219 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 301:\n",
      "Test Data: [1.71333076 1.5678025  1.22021571]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 302:\n",
      "Test Data: [3.59763058 4.37997531 1.2124168 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 303:\n",
      "Test Data: [ 6.97993463 23.11540603  1.20855061]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 304:\n",
      "Test Data: [6.68778584 1.35451835 0.98886158]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 305:\n",
      "Test Data: [7.20079958 0.3227149  1.1336863 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 306:\n",
      "Test Data: [1.36769663 0.78053522 1.20277285]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 307:\n",
      "Test Data: [4.08247592 0.39102498 1.11967464]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 308:\n",
      "Test Data: [2.77135046 1.90855586 1.21575901]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 309:\n",
      "Test Data: [10.59543736  8.7313425   1.13131051]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 310:\n",
      "Test Data: [3.45806976 1.61984174 1.19624432]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 311:\n",
      "Test Data: [4.10991805 1.67674519 1.17946197]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 312:\n",
      "Test Data: [4.94575344 0.29140823 0.89729295]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 313:\n",
      "Test Data: [2.32799713 4.11492939 1.22396295]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 314:\n",
      "Test Data: [1.91282512 6.35136569 1.20433159]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 315:\n",
      "Test Data: [1.7220095  0.77132225 1.22121352]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 316:\n",
      "Test Data: [5.27032722 0.11246315 1.20338939]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 317:\n",
      "Test Data: [ 3.71848918 17.20441507  1.22179027]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 318:\n",
      "Test Data: [ 4.61572388 15.80573403  1.2239156 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 319:\n",
      "Test Data: [10.83114825  0.31553357  0.94816825]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 320:\n",
      "Test Data: [4.65393499 0.23614194 1.14814519]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 321:\n",
      "Test Data: [3.72753754 2.54580655 1.12869044]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 322:\n",
      "Test Data: [ 4.53300079 15.35557718  1.22401248]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 323:\n",
      "Test Data: [9.89770673 4.88328889 1.11624427]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 324:\n",
      "Test Data: [2.5938226  0.263709   1.19900228]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 325:\n",
      "Test Data: [4.13054902e+01 1.07906425e-02 8.80912407e-01]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 326:\n",
      "Test Data: [3.41699579 0.30149276 1.1617236 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 327:\n",
      "Test Data: [2.68541601 1.75677381 1.2168725 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 328:\n",
      "Test Data: [0.60937399 1.10952789 1.04523634]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 329:\n",
      "Test Data: [2.29275309 1.65276405 1.22331572]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 330:\n",
      "Test Data: [0.74182575 0.2470244  1.08523902]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 331:\n",
      "Test Data: [0.64253202 0.64519018 1.0588579 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 332:\n",
      "Test Data: [0.74886893 0.26058918 1.08733274]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 333:\n",
      "Test Data: [1.05567044 0.46465719 1.15754569]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 334:\n",
      "Test Data: [2.56108566 4.15440798 1.22472552]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 335:\n",
      "Test Data: [10.82489909  0.09213356  1.13850112]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 336:\n",
      "Test Data: [1.94991846 1.18022089 1.2246313 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 337:\n",
      "Test Data: [1.49933051 0.12479537 1.16763252]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 338:\n",
      "Test Data: [2.24154645 0.40354332 1.18012303]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 339:\n",
      "Test Data: [4.48040041 0.31750387 1.18428435]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 340:\n",
      "Test Data: [5.57935695 1.9997832  1.07099596]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 341:\n",
      "Test Data: [4.71950018 2.40505324 1.10010937]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 342:\n",
      "Test Data: [3.98300501 3.65165194 1.19974828]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 343:\n",
      "Test Data: [2.09924729 0.12813826 1.20628744]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 344:\n",
      "Test Data: [7.58325682 2.09730388 1.05464725]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 345:\n",
      "Test Data: [11.73872308  7.99446215  1.11761415]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 346:\n",
      "Test Data: [1.25710254 0.63752225 1.19029297]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 347:\n",
      "Test Data: [9.94505408 0.27028221 1.10746829]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 348:\n",
      "Test Data: [ 3.79749552 10.00313467  1.21719547]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 349:\n",
      "Test Data: [1.29608286 0.14080713 1.15305648]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 350:\n",
      "Test Data: [3.99989572 4.53709424 1.16969075]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 351:\n",
      "Test Data: [16.21138796 33.97864537  1.15081371]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 352:\n",
      "Test Data: [ 4.23670877 13.87112932  1.22436435]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 353:\n",
      "Test Data: [2.8582878  2.75474551 0.90602104]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 354:\n",
      "Test Data: [2.05761388 5.53220988 1.21407145]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 355:\n",
      "Test Data: [0.90006421 3.24289711 1.12113737]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 356:\n",
      "Test Data: [0.2099964  1.22743679 0.85031895]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 357:\n",
      "Test Data: [135.71167283 235.74123423   0.94277323]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 358:\n",
      "Test Data: [1.46966822 0.61849412 1.20856333]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 359:\n",
      "Test Data: [1.47572894 0.15280075 1.17375404]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 360:\n",
      "Test Data: [0.6201676  1.27005143 1.04978513]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 361:\n",
      "Test Data: [5.01130999 0.08080114 1.2167762 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 362:\n",
      "Test Data: [1.85495911 4.74964446 1.20974676]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 363:\n",
      "Test Data: [1.24396145 0.22796696 1.16486742]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 364:\n",
      "Test Data: [2.29905726 3.73964441 1.22423812]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 365:\n",
      "Test Data: [0.07356865 1.66002897 0.70148234]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 366:\n",
      "Test Data: [12.71977894  0.05886401  1.13202727]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 367:\n",
      "Test Data: [1.91955857 0.23813476 1.21511941]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 368:\n",
      "Test Data: [3.03407308 2.75874237 1.15834024]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 369:\n",
      "Test Data: [2.35345856 3.10923998 1.22473279]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 370:\n",
      "Test Data: [4.7130622  6.07997802 1.20016733]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 371:\n",
      "Test Data: [2.47099935 2.21604492 1.22249811]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 372:\n",
      "Test Data: [0.93051291 0.48357956 1.13502741]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 373:\n",
      "Test Data: [9.99188143 0.03696397 1.18414239]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 374:\n",
      "Test Data: [0.14325345 0.40614071 0.87364524]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 375:\n",
      "Test Data: [1.26062104 0.30920846 1.17620089]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 376:\n",
      "Test Data: [8.23897115 0.09443181 1.14967958]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 377:\n",
      "Test Data: [5.42553624 0.65631055 1.14857183]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 378:\n",
      "Test Data: [ 7.9748928  39.21635878  1.21994894]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 379:\n",
      "Test Data: [3.2606011  3.38611034 1.16844569]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 380:\n",
      "Test Data: [1.58463351 0.6936536  1.21585948]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 381:\n",
      "Test Data: [13.49076502  0.19954912  1.06511386]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 382:\n",
      "Test Data: [ 17.01792511 150.41207321   1.21385109]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 383:\n",
      "Test Data: [2.22173674 3.68274322 1.22364919]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 384:\n",
      "Test Data: [2.45448614 0.90772323 1.2195396 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 385:\n",
      "Test Data: [3.45959123 8.06685059 1.22402128]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 386:\n",
      "Test Data: [2.202654   1.50069153 1.2239878 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 387:\n",
      "Test Data: [1.03437158 2.04899985 1.15481142]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 388:\n",
      "Test Data: [0.04072182 0.81830484 0.74186876]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 389:\n",
      "Test Data: [6.96887506 0.13407041 1.14511087]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 390:\n",
      "Test Data: [1.99534229 0.10801704 1.21682059]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 391:\n",
      "Test Data: [4.85266204 0.0535181  1.22194358]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 392:\n",
      "Test Data: [5.0948511  0.1313992  1.17980758]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 393:\n",
      "Test Data: [12.45475836 42.25663218  1.18553804]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 394:\n",
      "Test Data: [0.62723318 2.42577321 1.05710938]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 395:\n",
      "Test Data: [2.09436909 4.42434094 1.21943184]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 396:\n",
      "Test Data: [1.04264495 0.22439367 1.13747874]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 397:\n",
      "Test Data: [1.76045853 0.33143996 1.21505178]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 398:\n",
      "Test Data: [0.72696105 1.90544176 1.0858967 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 399:\n",
      "Test Data: [5.37710967 1.92759631 1.07072256]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 400:\n",
      "Test Data: [2.52836473 0.3181839  1.22398509]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 401:\n",
      "Test Data: [1.45828766 0.20997702 1.18387361]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 402:\n",
      "Test Data: [3.06801333 0.15251153 1.224572  ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 403:\n",
      "Test Data: [3.87630537 3.69852679 1.20246941]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 404:\n",
      "Test Data: [3.24017959 6.70777053 1.22392405]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 405:\n",
      "Test Data: [5.64293767 5.76167778 1.18080532]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 406:\n",
      "Test Data: [4.24745612 6.87727093 1.1915106 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 407:\n",
      "Test Data: [0.41227575 0.3538065  0.99075518]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 408:\n",
      "Test Data: [3.1165791  1.48547069 1.20462449]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 409:\n",
      "Test Data: [2.18911791 1.40159467 1.22398285]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 410:\n",
      "Test Data: [0.26737731 0.43445838 0.92254079]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 411:\n",
      "Test Data: [1.12718583 0.22957248 1.15029955]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 412:\n",
      "Test Data: [9.14141172 1.17744786 0.99710475]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 413:\n",
      "Test Data: [6.61041277 0.27322674 1.10179845]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 414:\n",
      "Test Data: [18.61249311 23.72121457  1.11232031]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 415:\n",
      "Test Data: [3.41687079 0.1369417  1.21211648]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 416:\n",
      "Test Data: [0.62584051 0.5041195  1.05505821]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 417:\n",
      "Test Data: [1.38890588 0.15972986 1.21223341]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 418:\n",
      "Test Data: [6.30593946 0.04600767 1.21795047]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 419:\n",
      "Test Data: [5.13014472 0.05637678 1.2225965 ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 420:\n",
      "Test Data: [3.37211429 0.79044894 1.00761269]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 421:\n",
      "Test Data: [2.38041269 0.68254448 1.22165267]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 422:\n",
      "Test Data: [2.93296355 1.59517548 1.21011371]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 423:\n",
      "Test Data: [1.11901766 2.62127051 1.16327504]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 424:\n",
      "Test Data: [3.20766126 3.2519284  1.21405335]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 425:\n",
      "Test Data: [2.7819787  2.55463552 1.21878239]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 426:\n",
      "Test Data: [1.76571053 0.30146222 1.217344  ]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 427:\n",
      "Test Data: [2.32353494 0.56895236 1.22317729]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 428:\n",
      "Test Data: [5.2834425  0.04648223 1.22168416]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 429:\n",
      "Test Data: [9.2489483  0.0261743  1.21073681]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 430:\n",
      "Test Data: [6.71486766 1.93095448 0.82524687]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 431:\n",
      "Test Data: [6.84868506 1.80354882 1.05046812]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 432:\n",
      "Test Data: [ 6.90209634 26.20122723  1.21775723]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 433:\n",
      "Test Data: [2.54260688 0.17719138 1.21898846]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 434:\n",
      "Test Data: [4.67176522 0.08591701 1.20997719]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 435:\n",
      "Test Data: [3.65213244 3.9184181  1.16815246]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 436:\n",
      "Test Data: [4.58596198 0.24809896 1.14587564]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 437:\n",
      "Test Data: [1.49171221 0.30859534 1.19806917]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 438:\n",
      "Test Data: [12.91452186  8.13774115  1.09101546]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 439:\n",
      "Test Data: [3.59627173 5.3954189  1.19230224]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 440:\n",
      "Test Data: [3.67036227 2.26612981 1.19599326]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 441:\n",
      "Test Data: [2.324897   0.85249565 1.22195456]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 442:\n",
      "Test Data: [ 7.45900223 11.80801599  1.16714211]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 443:\n",
      "Test Data: [0.20036669 0.44514558 0.89039618]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 444:\n",
      "Test Data: [1.23674828 2.7961236  1.17727562]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Iteration 445:\n",
      "Test Data: [3.25707151 0.13830875 1.22430739]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [0.]\n",
      "Accuracy (Final Layer): 1.0\n",
      "\n",
      "Iteration 446:\n",
      "Test Data: [2.16101396 7.11054527 1.21139526]\n",
      "Actual Label: 0.0\n",
      "Predicted Label (Final Layer): [1.]\n",
      "Accuracy (Final Layer): 0.0\n",
      "\n",
      "Mean Accuracy (Final Layer): 0.625560538116592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def layer1(X_train, y_train):\n",
    "    # Define your classifier (Random Forest Classifier)\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Fit the classifier on the entire dataset to obtain predictions\n",
    "    y_pred =  clf.predict(X_train)\n",
    "\n",
    "    # Extract positively predicted samples and their labels\n",
    "    positively_predicted_samples1 = X_train[y_pred == y_train]\n",
    "    actual_labels_positively_predicted1 = y_train[y_pred == y_train]\n",
    "\n",
    "\n",
    "    return positively_predicted_samples1, actual_labels_positively_predicted1\n",
    "\n",
    "# Assuming X and Y are your original datasets\n",
    "def layer2(X_layer1, y_layer1):\n",
    "\n",
    "    # Define your classifier (Random Forest Classifier)\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_layer1, y_layer1)\n",
    "\n",
    "    # Fit the classifier on the entire dataset to obtain predictions\n",
    "    y_pred =  clf.predict(X_layer1)\n",
    "\n",
    "    # Extract positively predicted samples and their labels\n",
    "    positively_predicted_samples2 = X_layer1[y_pred == y_layer1]\n",
    "    actual_labels_positively_predicted2 = y_layer1[y_pred == y_layer1]\n",
    "    return positively_predicted_samples2, actual_labels_positively_predicted2,clf\n",
    "\n",
    "# Placeholder for results\n",
    "final_layer_accuracies = []\n",
    "\n",
    "# Create a Leave-One-Out Cross-Validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Iterate through the Leave-One-Out splits\n",
    "for test_index in range(len(X)):\n",
    "    # Create training set (X_train, Y_train) without the test data point\n",
    "    X_train = np.delete(X, test_index, axis=0)\n",
    "    Y_train = np.delete(Y, test_index)\n",
    "\n",
    "    # Call layer1 function\n",
    "    positively_predicted_samples1, actual_labels_positively_predicted1 = layer1(X_train, Y_train)\n",
    "\n",
    "    # Call layer2 function using the output of layer1\n",
    "    positively_predicted_samples2, actual_labels_positively_predicted2,clf  = layer2(positively_predicted_samples1, actual_labels_positively_predicted1)\n",
    "\n",
    "    # Create training set using only layer3 output\n",
    "    X_final_layer = positively_predicted_samples2\n",
    "    Y_final_layer = actual_labels_positively_predicted2\n",
    "\n",
    "    # Test on the left-out data point from the original dataset\n",
    "    y_pred_final_layer = clf.predict(X[test_index].reshape(1, -1))\n",
    "\n",
    "    # Calculate accuracy for the fold\n",
    "    accuracy_final_layer = accuracy_score([Y[test_index]], y_pred_final_layer)\n",
    "\n",
    "    # Store results\n",
    "    final_layer_accuracies.append(accuracy_final_layer)\n",
    "\n",
    "    # Print information for the current iteration\n",
    "    print(f\"Iteration {test_index + 1}:\")\n",
    "    print(f\"Test Data: {X[test_index]}\")\n",
    "    print(f\"Actual Label: {Y[test_index]}\")\n",
    "    print(f\"Predicted Label (Final Layer): {y_pred_final_layer}\")\n",
    "    print(f\"Accuracy (Final Layer): {accuracy_final_layer}\")\n",
    "    print()\n",
    "\n",
    "# Calculate mean accuracy for the final layer\n",
    "mean_accuracy_final_layer = np.mean(final_layer_accuracies)\n",
    "print(\"Mean Accuracy (Final Layer):\", mean_accuracy_final_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "def layer1(X_train, y_train):\n",
    "    # Define your classifier (Random Forest Classifier)\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a Leave-One-Out Cross-Validator\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    accuracies = 0\n",
    "\n",
    "    # Perform cross-validation and get accuracy for each iteration\n",
    "    #accuracies = cross_val_score(clf, X_train, y_train, cv=loo)\n",
    "\n",
    "    # Fit the classifier on the entire dataset to obtain predictions\n",
    "    y_pred = cross_val_predict(clf, X_train, y_train, cv=loo, n_jobs=7)\n",
    "\n",
    "    # Extract positively predicted samples and their labels\n",
    "    positively_predicted_samples1 = X_train[y_pred == y_train]\n",
    "    actual_labels_positively_predicted1 = y_train[y_pred == y_train]\n",
    "\n",
    "\n",
    "    return positively_predicted_samples1, actual_labels_positively_predicted1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "def layer2(X_layer1, y_layer1):\n",
    "    # Define your classifier (Random Forest Classifier)\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a Leave-One-Out Cross-Validator\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    accuracies = 0\n",
    "\n",
    "    # Perform cross-validation and get accuracy for each iteration\n",
    "    #accuracies = cross_val_score(clf, X_layer1, y_layer1, cv=loo)\n",
    "\n",
    "    # Fit the classifier on the entire dataset to obtain predictions\n",
    "    y_pred = cross_val_predict(clf, X_layer1, y_layer1, cv=loo)\n",
    "\n",
    "    # Extract positively predicted samples and their labels\n",
    "    positively_predicted_samples2 = X_layer1[y_pred == y_layer1]\n",
    "    actual_labels_positively_predicted2 = y_layer1[y_pred == y_layer1]\n",
    "\n",
    "    clf.fit(X_layer1, y_layer1)\n",
    "\n",
    "\n",
    "    # Return results if needed\n",
    "    return positively_predicted_samples2, actual_labels_positively_predicted2,clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "def layer3(X_layer2, y_layer2):\n",
    "    # Define your classifier (Random Forest Classifier)\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a Leave-One-Out Cross-Validator\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "\n",
    "    accuracies = 0\n",
    "\n",
    "    # Perform cross-validation and get accuracy for each iteration\n",
    "    #accuracies = cross_val_score(clf, X_layer2, y_layer2, cv=loo)\n",
    "\n",
    "\n",
    "    # Fit the classifier on the entire dataset to obtain predictions\n",
    "    y_pred = cross_val_predict(clf, X_layer2, y_layer2, cv=loo, n_jobs=6)\n",
    "\n",
    "    # Extract positively predicted samples and their labels\n",
    "    positively_predicted_samples3 = X_layer2[y_pred == y_layer2]\n",
    "    actual_labels_positively_predicted3 = y_layer2[y_pred == y_layer2]\n",
    "\n",
    "    # Print mean accuracy and extracted samples\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    clf.fit(X_layer2, y_layer2)\n",
    "    # Test on the left-out data point from the original dataset\n",
    "    \n",
    "\n",
    "    #print(\"\\nMean Accuracy (Layer 3):\", mean_accuracy)\n",
    "    #print(\"\\nPositively Predicted Samples (Layer 3):\")\n",
    "    #print(positively_predicted_samples.shape)\n",
    "    #print(\"\\nCorresponding Labels (Layer 3):\")\n",
    "    #print(actual_labels_positively_predicted.shape)\n",
    "\n",
    "    # Return results if needed otherwise you shouldn't return anything \n",
    "    return positively_predicted_samples3, actual_labels_positively_predicted3, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X and Y are your original datasets\n",
    "\n",
    "# Placeholder for results\n",
    "final_layer_accuracies = []\n",
    "\n",
    "# Create a Leave-One-Out Cross-Validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Iterate through the Leave-One-Out splits\n",
    "for test_index in range(len(X)):\n",
    "    # Create training set (X_train, Y_train) without the test data point\n",
    "    X_train = np.delete(X, test_index, axis=0)\n",
    "    Y_train = np.delete(Y, test_index)\n",
    "\n",
    "    # Call layer1 function\n",
    "    positively_predicted_samples1, actual_labels_positively_predicted1 = layer1(X_train, Y_train)\n",
    "\n",
    "    # Call layer2 function using the output of layer1\n",
    "    positively_predicted_samples2, actual_labels_positively_predicted2,clf  = layer2(positively_predicted_samples1, actual_labels_positively_predicted1)\n",
    "\n",
    "    # Create training set using only layer3 output\n",
    "    X_final_layer = positively_predicted_samples2\n",
    "    Y_final_layer = actual_labels_positively_predicted2\n",
    "\n",
    "    # Test on the left-out data point from the original dataset\n",
    "    y_pred_final_layer = clf.predict(X[test_index].reshape(1, -1))\n",
    "\n",
    "    # Calculate accuracy for the fold\n",
    "    accuracy_final_layer = accuracy_score([Y[test_index]], y_pred_final_layer)\n",
    "\n",
    "    # Store results\n",
    "    final_layer_accuracies.append(accuracy_final_layer)\n",
    "\n",
    "    # Print information for the current iteration\n",
    "    print(f\"Iteration {test_index + 1}:\")\n",
    "    print(f\"Test Data: {X[test_index]}\")\n",
    "    print(f\"Actual Label: {Y[test_index]}\")\n",
    "    print(f\"Predicted Label (Final Layer): {y_pred_final_layer}\")\n",
    "    print(f\"Accuracy (Final Layer): {accuracy_final_layer}\")\n",
    "    print()\n",
    "\n",
    "# Calculate mean accuracy for the final layer\n",
    "mean_accuracy_final_layer = np.mean(final_layer_accuracies)\n",
    "print(\"Mean Accuracy (Final Layer):\", mean_accuracy_final_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelizing For loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X and Y are your original datasets\n",
    "\n",
    "# Placeholder for results\n",
    "final_layer_accuracies = []\n",
    "\n",
    "# Create a Leave-One-Out Cross-Validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "def process_iteration(test_index, X, Y):\n",
    "    # Create training set (X_train, Y_train) without the test data point\n",
    "    X_train = np.delete(X, test_index, axis=0)\n",
    "    Y_train = np.delete(Y, test_index)\n",
    "\n",
    "    # Call layer1 function\n",
    "    positively_predicted_samples1, actual_labels_positively_predicted1 = layer1(X_train, Y_train)\n",
    "\n",
    "    # Call layer2 function using the output of layer1\n",
    "    positively_predicted_samples2, actual_labels_positively_predicted2, clf = layer2(positively_predicted_samples1, actual_labels_positively_predicted1)\n",
    "\n",
    "    # Call layer3 function using the output of layer2\n",
    "    # positively_predicted_samples3, actual_labels_positively_predicted3, clf = layer3(positively_predicted_samples2, actual_labels_positively_predicted2)\n",
    "\n",
    "    # Create training set using only layer3 output\n",
    "    X_final_layer = positively_predicted_samples2\n",
    "    Y_final_layer = actual_labels_positively_predicted2\n",
    "\n",
    "    # Test on the left-out data point from the original dataset\n",
    "    y_pred_final_layer = clf.predict(X[test_index].reshape(1, -1))\n",
    "\n",
    "    # Calculate accuracy for the fold\n",
    "    accuracy_final_layer = accuracy_score([Y[test_index]], y_pred_final_layer)\n",
    "\n",
    "   \n",
    "    return accuracy_final_layer\n",
    "\n",
    "# Parallelize the loop\n",
    "final_layer_accuracies = Parallel(n_jobs= 7)(delayed(process_iteration)(test_index, X, Y) for test_index in range(len(X)))\n",
    "\n",
    "# Calculate mean accuracy for the final layer\n",
    "mean_accuracy_final_layer = np.mean(final_layer_accuracies)\n",
    "print(\"Mean Accuracy (Final Layer):\", mean_accuracy_final_layer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
